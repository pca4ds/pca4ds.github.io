<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 How Does PCA Work? | Principal Component Analysis for Data Science (PCA4DS)</title>
  <meta name="description" content="This book will teach you what is Principal Component Analysis and how you can use it for a variety of data analysis purposes: description, exploration, visualization, pre-modeling, dimension reduction, and data compression." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="2 How Does PCA Work? | Principal Component Analysis for Data Science (PCA4DS)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book will teach you what is Principal Component Analysis and how you can use it for a variety of data analysis purposes: description, exploration, visualization, pre-modeling, dimension reduction, and data compression." />
  <meta name="github-repo" content="gastonstat/pca4ds" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 How Does PCA Work? | Principal Component Analysis for Data Science (PCA4DS)" />
  
  <meta name="twitter:description" content="This book will teach you what is Principal Component Analysis and how you can use it for a variety of data analysis purposes: description, exploration, visualization, pre-modeling, dimension reduction, and data compression." />
  

<meta name="author" content="Tomas Aluja-Banet Alain Morineau Gaston Sanchez" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basic.html"/>
<link rel="next" href="analysis.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><b>PCA for Data Science</b><br><small>T. Aluja, A. Morineau, G. Sanchez</small></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i>Terminology</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="basic.html"><a href="basic.html"><i class="fa fa-check"></i><b>1</b> Basic Elements</a><ul>
<li class="chapter" data-level="1.1" data-path="basic.html"><a href="basic.html#data-and-goals"><i class="fa fa-check"></i><b>1.1</b> Data and Goals</a><ul>
<li class="chapter" data-level="1.1.1" data-path="basic.html"><a href="basic.html#active-variables"><i class="fa fa-check"></i><b>1.1.1</b> Active Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="basic.html"><a href="basic.html#analysis-of-distances"><i class="fa fa-check"></i><b>1.2</b> Analysis of Distances</a><ul>
<li class="chapter" data-level="1.2.1" data-path="basic.html"><a href="basic.html#cloud-of-row-points"><i class="fa fa-check"></i><b>1.2.1</b> Cloud of Row-Points</a></li>
<li class="chapter" data-level="1.2.2" data-path="basic.html"><a href="basic.html#cloud-of-column-points"><i class="fa fa-check"></i><b>1.2.2</b> Cloud of Column-Points</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="basic.html"><a href="basic.html#how-to-see-the-distances-between-points"><i class="fa fa-check"></i><b>1.3</b> How to see the distances between points</a><ul>
<li class="chapter" data-level="1.3.1" data-path="basic.html"><a href="basic.html#how-to-find-the-projection-planes"><i class="fa fa-check"></i><b>1.3.1</b> How to find the projection planes</a></li>
<li class="chapter" data-level="1.3.2" data-path="basic.html"><a href="basic.html#how-to-take-into-account-the-importance-of-individuals"><i class="fa fa-check"></i><b>1.3.2</b> How to take into account the importance of individuals</a></li>
<li class="chapter" data-level="1.3.3" data-path="basic.html"><a href="basic.html#inertia-decomposition"><i class="fa fa-check"></i><b>1.3.3</b> Inertia Decomposition</a></li>
<li class="chapter" data-level="1.3.4" data-path="basic.html"><a href="basic.html#visualizing-association-between-variables."><i class="fa fa-check"></i><b>1.3.4</b> Visualizing association between variables.</a></li>
<li class="chapter" data-level="1.3.5" data-path="basic.html"><a href="basic.html#normalized-pca-or-non-normalized-pca"><i class="fa fa-check"></i><b>1.3.5</b> Normalized PCA or non-normalized PCA?</a></li>
<li class="chapter" data-level="1.3.6" data-path="basic.html"><a href="basic.html#distance-matrices"><i class="fa fa-check"></i><b>1.3.6</b> Distance Matrices</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Mechanics</b></span></li>
<li class="chapter" data-level="2" data-path="mechanics.html"><a href="mechanics.html"><i class="fa fa-check"></i><b>2</b> How Does PCA Work?</a><ul>
<li class="chapter" data-level="2.1" data-path="mechanics.html"><a href="mechanics.html#principal-components"><i class="fa fa-check"></i><b>2.1</b> Principal Components</a><ul>
<li class="chapter" data-level="2.1.1" data-path="mechanics.html"><a href="mechanics.html#interpreting-the-inertia-proportions"><i class="fa fa-check"></i><b>2.1.1</b> Interpreting the Inertia Proportions</a></li>
<li class="chapter" data-level="2.1.2" data-path="mechanics.html"><a href="mechanics.html#how-many-axes-to-retain"><i class="fa fa-check"></i><b>2.1.2</b> How many axes to retain?</a></li>
<li class="chapter" data-level="2.1.3" data-path="mechanics.html"><a href="mechanics.html#coordinates-of-row-points"><i class="fa fa-check"></i><b>2.1.3</b> Coordinates of row-points</a></li>
<li class="chapter" data-level="2.1.4" data-path="mechanics.html"><a href="mechanics.html#interpretation-tools"><i class="fa fa-check"></i><b>2.1.4</b> Interpretation Tools</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="mechanics.html"><a href="mechanics.html#projections-of-variables"><i class="fa fa-check"></i><b>2.2</b> Projections of Variables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="mechanics.html"><a href="mechanics.html#size-effect"><i class="fa fa-check"></i><b>2.2.1</b> Size Effect</a></li>
<li class="chapter" data-level="2.2.2" data-path="mechanics.html"><a href="mechanics.html#tools-for-interpreting-components"><i class="fa fa-check"></i><b>2.2.2</b> Tools for Interpreting Components</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="mechanics.html"><a href="mechanics.html#size-factor"><i class="fa fa-check"></i><b>2.3</b> Beyond the First Factor</a></li>
<li class="chapter" data-level="2.4" data-path="mechanics.html"><a href="mechanics.html#using-supplementary-elements"><i class="fa fa-check"></i><b>2.4</b> Using Supplementary Elements</a><ul>
<li class="chapter" data-level="2.4.1" data-path="mechanics.html"><a href="mechanics.html#continuous-supplementary-variables"><i class="fa fa-check"></i><b>2.4.1</b> Continuous Supplementary Variables</a></li>
<li class="chapter" data-level="2.4.2" data-path="mechanics.html"><a href="mechanics.html#nominal-supplementary-variables"><i class="fa fa-check"></i><b>2.4.2</b> Nominal Supplementary Variables</a></li>
<li class="chapter" data-level="2.4.3" data-path="mechanics.html"><a href="mechanics.html#profiling-with-v-test"><i class="fa fa-check"></i><b>2.4.3</b> Profiling with V-test</a></li>
<li class="chapter" data-level="2.4.4" data-path="mechanics.html"><a href="mechanics.html#axes-characterization-using-continuous-variables"><i class="fa fa-check"></i><b>2.4.4</b> Axes Characterization using Continuous Variables</a></li>
<li class="chapter" data-level="2.4.5" data-path="mechanics.html"><a href="mechanics.html#v-test-and-data-science"><i class="fa fa-check"></i><b>2.4.5</b> V-test and Data Science</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="mechanics.html"><a href="mechanics.html#simultaneous-representations"><i class="fa fa-check"></i><b>2.5</b> Simultaneous Representations</a><ul>
<li class="chapter" data-level="2.5.1" data-path="mechanics.html"><a href="mechanics.html#old-unit-axes"><i class="fa fa-check"></i><b>2.5.1</b> Old Unit Axes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Practice</b></span></li>
<li class="chapter" data-level="3" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>3</b> Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis.html"><a href="analysis.html#themescope"><i class="fa fa-check"></i><b>3.1</b> Themescope</a></li>
<li class="chapter" data-level="3.2" data-path="analysis.html"><a href="analysis.html#conditions-of-application"><i class="fa fa-check"></i><b>3.2</b> Conditions of Application</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis.html"><a href="analysis.html#linearity-and-symmetry"><i class="fa fa-check"></i><b>3.2.1</b> Linearity and Symmetry</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis.html"><a href="analysis.html#balancing-the-content-of-active-variables"><i class="fa fa-check"></i><b>3.2.2</b> Balancing the content of active variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis.html"><a href="analysis.html#validation-stability-and-significance"><i class="fa fa-check"></i><b>3.3</b> Validation: stability and significance</a><ul>
<li class="chapter" data-level="3.3.1" data-path="analysis.html"><a href="analysis.html#how-many-axes-to-study-and-retain"><i class="fa fa-check"></i><b>3.3.1</b> How many axes to study and retain?</a></li>
<li class="chapter" data-level="3.3.2" data-path="analysis.html"><a href="analysis.html#simulations-random-effects-on-individuals"><i class="fa fa-check"></i><b>3.3.2</b> Simulations, random effects on individuals</a></li>
<li class="chapter" data-level="3.3.3" data-path="analysis.html"><a href="analysis.html#bootstrap-simulations"><i class="fa fa-check"></i><b>3.3.3</b> Bootstrap Simulations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="analysis.html"><a href="analysis.html#analysis-of-table-of-ranks"><i class="fa fa-check"></i><b>3.4</b> Analysis of Table of Ranks</a></li>
<li class="chapter" data-level="3.5" data-path="analysis.html"><a href="analysis.html#optimal-reconstitution-of-data"><i class="fa fa-check"></i><b>3.5</b> Optimal Reconstitution of Data</a></li>
<li class="chapter" data-level="3.6" data-path="analysis.html"><a href="analysis.html#synthetic-variables-and-indices"><i class="fa fa-check"></i><b>3.6</b> Synthetic Variables and Indices</a></li>
<li class="chapter" data-level="3.7" data-path="analysis.html"><a href="analysis.html#handling-missing-values"><i class="fa fa-check"></i><b>3.7</b> Handling Missing Values</a></li>
<li class="chapter" data-level="3.8" data-path="analysis.html"><a href="analysis.html#pca-and-clustering"><i class="fa fa-check"></i><b>3.8</b> PCA and Clustering</a><ul>
<li class="chapter" data-level="3.8.1" data-path="analysis.html"><a href="analysis.html#real-groups-or-instrumental-groups"><i class="fa fa-check"></i><b>3.8.1</b> Real Groups or Instrumental Groups?</a></li>
<li class="chapter" data-level="3.8.2" data-path="analysis.html"><a href="analysis.html#representants-of-groups"><i class="fa fa-check"></i><b>3.8.2</b> Representants of Groups</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="analysis.html"><a href="analysis.html#data-weighing"><i class="fa fa-check"></i><b>3.9</b> Data Weighing</a></li>
<li class="chapter" data-level="3.10" data-path="analysis.html"><a href="analysis.html#pca-as-an-intermediate-analytical-stage"><i class="fa fa-check"></i><b>3.10</b> PCA as an Intermediate Analytical Stage</a></li>
<li class="chapter" data-level="3.11" data-path="analysis.html"><a href="analysis.html#comparing-various-tables"><i class="fa fa-check"></i><b>3.11</b> Comparing Various Tables</a></li>
<li class="chapter" data-level="3.12" data-path="analysis.html"><a href="analysis.html#analysis-of-a-table-of-means"><i class="fa fa-check"></i><b>3.12</b> Analysis of a Table of Means</a></li>
<li class="chapter" data-level="3.13" data-path="analysis.html"><a href="analysis.html#analysis-of-a-binary-table"><i class="fa fa-check"></i><b>3.13</b> Analysis of a Binary Table</a></li>
<li class="chapter" data-level="3.14" data-path="analysis.html"><a href="analysis.html#analysis-of-a-table-of-distances"><i class="fa fa-check"></i><b>3.14</b> Analysis of a Table of Distances</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="4" data-path="appendixa.html"><a href="appendixa.html"><i class="fa fa-check"></i><b>4</b> Appendix A: Fundamentals</a><ul>
<li class="chapter" data-level="4.1" data-path="appendixa.html"><a href="appendixa.html#space-of-p-dimensions"><i class="fa fa-check"></i><b>4.1</b> Space of <span class="math inline">\(p\)</span> Dimensions</a></li>
<li class="chapter" data-level="4.2" data-path="appendixa.html"><a href="appendixa.html#distances-between-points"><i class="fa fa-check"></i><b>4.2</b> Distances between points</a></li>
<li class="chapter" data-level="4.3" data-path="appendixa.html"><a href="appendixa.html#center-of-gravity"><i class="fa fa-check"></i><b>4.3</b> Center of Gravity</a></li>
<li class="chapter" data-level="4.4" data-path="appendixa.html"><a href="appendixa.html#inertia-of-a-cloud-of-points"><i class="fa fa-check"></i><b>4.4</b> Inertia of a cloud of points</a></li>
<li class="chapter" data-level="4.5" data-path="appendixa.html"><a href="appendixa.html#projection-of-the-cloud-of-points-on-a-line"><i class="fa fa-check"></i><b>4.5</b> Projection of the cloud of points on a line</a></li>
<li class="chapter" data-level="4.6" data-path="appendixa.html"><a href="appendixa.html#centered-and-standardized-variable"><i class="fa fa-check"></i><b>4.6</b> Centered and Standardized Variable</a></li>
<li class="chapter" data-level="4.7" data-path="appendixa.html"><a href="appendixa.html#correlation-coefficient"><i class="fa fa-check"></i><b>4.7</b> Correlation Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="appendixb.html"><a href="appendixb.html"><i class="fa fa-check"></i><b>5</b> Appendix B: PCA Formulae</a><ul>
<li class="chapter" data-level="5.1" data-path="appendixb.html"><a href="appendixb.html#general-analysis"><i class="fa fa-check"></i><b>5.1</b> General Analysis</a></li>
<li class="chapter" data-level="5.2" data-path="appendixb.html"><a href="appendixb.html#formulas-for-pca"><i class="fa fa-check"></i><b>5.2</b> Formulas for PCA</a></li>
<li class="chapter" data-level="5.3" data-path="appendixb.html"><a href="appendixb.html#biplot-and-pca"><i class="fa fa-check"></i><b>5.3</b> Biplot and PCA</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="appendixc.html"><a href="appendixc.html"><i class="fa fa-check"></i><b>6</b> Appendix C: Data Analysis Reminder</a><ul>
<li class="chapter" data-level="6.1" data-path="appendixc.html"><a href="appendixc.html#normalized-principal-component-analysis"><i class="fa fa-check"></i><b>6.1</b> Normalized Principal Component Analysis</a></li>
<li class="chapter" data-level="6.2" data-path="appendixc.html"><a href="appendixc.html#non-normalized-principal-component-analysis"><i class="fa fa-check"></i><b>6.2</b> Non-normalized Principal Component Analysis</a></li>
<li class="chapter" data-level="6.3" data-path="appendixc.html"><a href="appendixc.html#simple-correpondence-analysis"><i class="fa fa-check"></i><b>6.3</b> Simple Correpondence Analysis</a></li>
<li class="chapter" data-level="6.4" data-path="appendixc.html"><a href="appendixc.html#multiple-correspondence-analysis"><i class="fa fa-check"></i><b>6.4</b> Multiple Correspondence Analysis</a></li>
<li class="chapter" data-level="6.5" data-path="appendixc.html"><a href="appendixc.html#clustering-of-factors"><i class="fa fa-check"></i><b>6.5</b> Clustering of Factors</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Principal Component Analysis for Data Science (PCA4DS)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mechanics" class="section level1">
<h1><span class="header-section-number">2</span> How Does PCA Work?</h1>
<p>At its heart, performing a Principal Component Analysis involves taking a data table that contains the information about a certain phenomenon, in order to transform such data into a set of visual representations in some optimal sense. During the transformation process part of the information is “lost”. However, PCA seeks to minimize this loss of information. There is a tradeoff between the amount of information that is lost, in exchange of gaining understanding and insight. We go from a raw data table to a set of graphical representations that should be easier to understand. In order to be able to <em>read</em> the results and graphics obtained from a PCA, we need to discuss the mechanics of this technique and its underlying rationale.</p>
<div id="principal-components" class="section level2">
<h2><span class="header-section-number">2.1</span> Principal Components</h2>
<p>Let’s consider the cloud of row-points, also known as the cloud of individuals. As we’ve mentioned, we are interested in decomposing the inertia (i.e. the spread) of this cloud in terms of a series of orthogonal directions.</p>
<p>The first step consists of looking for the most basic type of subspace, namely, a line. Geometrically, a line can be defined by a vector <span class="math inline">\(\mathbf{u}\)</span> of unit norm. Based on the discusion from the previous chapter, we will attempt to define <span class="math inline">\(\mathbf{u}\)</span> in such a way that the projected points on this direction have maximum inertia (see figure <a href="mechanics.html#fig:fig-2-1">2.1</a>). In other words, <span class="math inline">\(\mathbf{u}\)</span> will be defined such that the distances between pairs of projected points are as close as possible to the original distances.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-1"></span>
<img src="images/figure-2-1.png" alt="Projection of a row-point on the direction defined by a unit vector" width="75%" />
<p class="caption">
Figure 2.1: Projection of a row-point on the direction defined by a unit vector
</p>
</div>
<p>The projection (or coordinate) of a row-point on the direction defined by <span class="math inline">\(\mathbf{u}\)</span> is given by:</p>
<p><span class="math display" id="eq:2-1">\[
\psi_i = \sum_{j=1}^{p} (x_{ij} - \bar{x}_j) u_j
\tag{2.1}
\]</span></p>
<p>The inertia (or variance) of all the projected points on <span class="math inline">\(\mathbf{u}\)</span> is then:</p>
<p><span class="math display" id="eq:2-2">\[
\sum_{i=1}^{n} = p_i \hspace{1mm} \psi_{i}^{2} = \lambda
\tag{2.2}
\]</span></p>
<p>The goal is to look for a line <span class="math inline">\(\mathbf{u}\)</span> that maximizes the value <span class="math inline">\(\lambda\)</span>.</p>
<p>Let <span class="math inline">\(\mathbf{X}\)</span> be the mean-centered data matrix. Obtaining <span class="math inline">\(\mathbf{u}\)</span> implies diagonalizing the cross-product matrix <span class="math inline">\(\mathbf{X^\mathsf{T} X}\)</span>. This matrix is the correlation matrix in a normalized PCA, whereas in a non-normalized PCA this matrix becomes the covariance matrix.</p>
<p>It turns out that the unit vector <span class="math inline">\(\mathbf{u}\)</span> is the eigenvector associated to the largest eigenvalue from diagonalizing <span class="math inline">\(\mathbf{X^\mathsf{T} X}\)</span>.</p>
<p>Analogously, the orthogonal direction to <span class="math inline">\(\mathbf{u}\)</span> that maximizes the projected inertia in this new direction corresponds to the eigenvector associated to the second largest eigenvalue from diagonalizing <span class="math inline">\(\mathbf{X^\mathsf{T} X}\)</span>. This maximized inertia is equal to the second eigenvalue, so on and so forth.</p>
<p>The eigenvalues provide the projected inertias on each of the desired directions. Moreover, the sum of the eigenvalues is the sum of the inertias on the orthogonal directions, and this sum is equal to the global inertia of the cloud of points.</p>
<table>
<thead>
<tr class="header">
<th align="center">Eigenvalues</th>
<th align="center">Eigenvectors</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\lambda_1\)</span></td>
<td align="center"><span class="math inline">\(\mathbf{u_1}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda_2\)</span></td>
<td align="center"><span class="math inline">\(\mathbf{u_2}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\dots\)</span></td>
<td align="center"><span class="math inline">\(\dots\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\lambda_p\)</span></td>
<td align="center"><span class="math inline">\(\mathbf{u_p}\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display" id="eq:2-3">\[
I_T = \lambda_1 + \lambda_2 + \dots + \lambda_p = \begin{cases}
  0 &amp; \text{in normalized PCA} \\
  \sum_{j=1}^{p} var(j) &amp; \text{in non-normalized PCA}
\end{cases}
\tag{2.3}
\]</span></p>
<p>The eigenvectors give the directions of maximum inertia y we call them factorial axes.</p>
<p>On these directions we project the individuals, obtaining what is called the <strong>principal components</strong> (see formula <a href="mechanics.html#eq:2-3">(2.3)</a>). As we can tell, each component is obtained as a linear combination of the original variables:</p>
<p><span class="math display">\[
\boldsymbol{\psi}_{\alpha} = u_1 \mathbf{x_1} + \dots + u_p \mathbf{x_p}
\]</span></p>
<p>Likewise, each component has a variance equal to its associated eigenvalue:</p>
<p><span class="math display">\[
var(\boldsymbol{\psi}_{\alpha}) = \lambda_\alpha
\]</span></p>
<p>In summary, a Principal Component Analysis can be seen as a technique in which we go from <span class="math inline">\(p\)</span> original variables <span class="math inline">\(\mathbf{x_j}\)</span>, each having an importance given by its variance, into <span class="math inline">\(p\)</span> new variables <span class="math inline">\(\boldsymbol{\psi}_{\alpha}\)</span>. These new variables are linear combination of the original variables, and have an importance given by their variance which turns out to be their eigenvalues (see figure <a href="mechanics.html#fig:fig-2-2">2.2</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-2"></span>
<img src="images/figure-2-2.png" alt="Change of basis and dimension reduction" width="75%" />
<p class="caption">
Figure 2.2: Change of basis and dimension reduction
</p>
</div>
<div id="interpreting-the-inertia-proportions" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Interpreting the Inertia Proportions</h3>
<p>In our working examples with the data about the cities, we obtain the following 12 eigenvalues:</p>
<table>
<caption><span id="tab:table-2-1">Table 2.1: </span>Distribution of eigenvalues.</caption>
<thead>
<tr class="header">
<th align="right">num</th>
<th align="right">eigenvalues</th>
<th align="right">percentage</th>
<th align="right">cumulative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">10.1390</td>
<td align="right">84.49</td>
<td align="right">84.49</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.8612</td>
<td align="right">7.18</td>
<td align="right">91.67</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.3248</td>
<td align="right">2.71</td>
<td align="right">94.37</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.1715</td>
<td align="right">1.43</td>
<td align="right">95.80</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.1484</td>
<td align="right">1.24</td>
<td align="right">97.04</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.0973</td>
<td align="right">0.81</td>
<td align="right">97.85</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.0682</td>
<td align="right">0.57</td>
<td align="right">98.42</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.0525</td>
<td align="right">0.44</td>
<td align="right">98.86</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.0505</td>
<td align="right">0.42</td>
<td align="right">99.28</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.0332</td>
<td align="right">0.28</td>
<td align="right">99.55</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="right">0.0309</td>
<td align="right">0.26</td>
<td align="right">99.81</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">0.0226</td>
<td align="right">0.19</td>
<td align="right">100.00</td>
</tr>
</tbody>
</table>
<p>Notice that we obtain a first principal component that stands out from the rest.</p>
<p>The column <code>eigenvalue</code> provides the explained inertia for each direction. The sum of all of the inertias corresponds to the global inertia of the cloud of cities. Observe that this global inertia is equal to 12, which is the number of variables. Recall that this is property from a normalized PCA.</p>
<p>The column <code>percentage</code>, in turn, expresses the porpotion of the explained inertia by each axis. As we can tell from the table, the first direction explains about 85% of the global inertia, which is contained in a 12-dimensional space. Because of the very large value of this principal component, one could be tempted to neglect the rest of the components. However, we’ll see that such an attitude is not excempt of risks. This does not imply that the rest of the components are useless or uninteresting. Quite the opposite, they may help reveal systematic patterns of variation in the data.</p>
<p>The last column of table <a href="mechanics.html#tab:table-2-1">2.1</a> provides the cumulative percentage of inertia. With the first three factorial axes we summarize about 95% of the inertia (or spread) of the cloud of points.</p>
</div>
<div id="how-many-axes-to-retain" class="section level3">
<h3><span class="header-section-number">2.1.2</span> How many axes to retain?</h3>
<p>From the previous results, we’ve seen that with the first principal components, we get to recover or capture most of the spread in the cloud of points. A natural question arises: How many axes should we keep?</p>
<p>This is actually not an easy question, and the truth is that there is no definitive answer. In order to attempt answering this question, we have to consider another inquiry: What will the axes be used for? Let’s see some examples.</p>
<p><strong>Example 1.</strong> One possibility involves using the axes to obtain a simple graphic representation of the data. In this case, the conventional number of axes to retain is 2, which are used to graph a scatter diagram: say we call these axes <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span>. With a third axis, we could even try to get a three-dimensional representation (<span class="math inline">\(F_1\)</span>, <span class="math inline">\(F_2\)</span>, and <span class="math inline">\(F_3\)</span>). Beyond three dimensions, we can’t get any visual representations.</p>
<p>Optionally, we could try to look at partial displays of the <span class="math inline">\(p\)</span>-dimensional space. For instance, we can get a scatterplot with <span class="math inline">\(F_2\)</span> and <span class="math inline">\(F_3\)</span>, and then another scatterplot with <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_4\)</span>. Keep in mind that all these partial views require a considerable “intelectual” effort. Why? Because of the fact that in any of these partial configurations, the distances between points come from compressed spaces in which some directions have dissapeared. If the goal is to simply obtain a two-dimensional visualization, it usually suffices with looking at the first factorial plane (<span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span>). To look “beyond” this plane, we will use outputs from clustering methods.</p>
<p><strong>Example 2.</strong> If the purpose is to keep the factorial axes as an intermediate stage of a clustering procedure, then this changes things drastically. In this situation, we want to retain several axes (so that we get to keep as much of the spread of the original variables). Usually we would discard those directions associated to the smallest eigenvalues. The reason to do this is because such directions typically reflect random fluctuations—“noise”—and not really a signal in the data.</p>
<p><strong>Example 3.</strong> If the goal is to use the factorial axes as explanatory variables in a regression model or in a classification model, we will try to keep a reduced number of axes, although not necessarily the first ones. It is certainly possible to find discriminant directions among axes that are not in the first positions.</p>
<p>As you can tell, deciding on the number of axes to retain is not that simple. This is a decision that is also linked to the stability of results.</p>
<p>We recommend not to blindly trust in automatic rules of thumb for deciding the number of directions to be kept. Our experience tells us that it is possible to find stable factorial axes with relatively small eigenvalue.</p>
<p><em>Note:</em> To decrease the percentage of inertia of each axis, one can add new uncorrelated variables to the data table (i.e. white noise). Doing so should not have an effect on the first factorial axes, which should still be able to capture most of the summarized “information”.</p>
</div>
<div id="coordinates-of-row-points" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Coordinates of row-points</h3>
<p>The table below contains the results about the cities with respect to the first three factorial axes:</p>
<table>
<caption><span id="tab:table-2-2">Table 2.2: </span>Results of the individuals</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">city</th>
<th align="right">wgt</th>
<th align="right">disto</th>
<th align="right">coord1</th>
<th align="right">coord2</th>
<th align="right">contr1</th>
<th align="right">contr2</th>
<th align="right">cosqr1</th>
<th align="right">cosqr2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="left">AbuDhabi</td>
<td align="right">1.96</td>
<td align="right">27.16</td>
<td align="right">2.17</td>
<td align="right">4.61</td>
<td align="right">0.91</td>
<td align="right">48.42</td>
<td align="right">0.17</td>
<td align="right">0.78</td>
</tr>
<tr class="even">
<td>2</td>
<td align="left">Amsterdam</td>
<td align="right">1.96</td>
<td align="right">3.22</td>
<td align="right">1.58</td>
<td align="right">-0.36</td>
<td align="right">0.48</td>
<td align="right">0.29</td>
<td align="right">0.77</td>
<td align="right">0.04</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="left">Athens</td>
<td align="right">1.96</td>
<td align="right">4.24</td>
<td align="right">-1.91</td>
<td align="right">-0.51</td>
<td align="right">0.71</td>
<td align="right">0.58</td>
<td align="right">0.86</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>4</td>
<td align="left">Bangkok</td>
<td align="right">1.96</td>
<td align="right">9.87</td>
<td align="right">-2.97</td>
<td align="right">0.82</td>
<td align="right">1.71</td>
<td align="right">1.53</td>
<td align="right">0.89</td>
<td align="right">0.07</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="left">Bogota</td>
<td align="right">1.96</td>
<td align="right">7.14</td>
<td align="right">-2.47</td>
<td align="right">0.66</td>
<td align="right">1.18</td>
<td align="right">0.99</td>
<td align="right">0.86</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>6</td>
<td align="left">Mumbai</td>
<td align="right">1.96</td>
<td align="right">21.11</td>
<td align="right">-4.56</td>
<td align="right">-0.31</td>
<td align="right">4.03</td>
<td align="right">0.22</td>
<td align="right">0.99</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="left">Brussels</td>
<td align="right">1.96</td>
<td align="right">0.74</td>
<td align="right">0.61</td>
<td align="right">-0.17</td>
<td align="right">0.07</td>
<td align="right">0.07</td>
<td align="right">0.50</td>
<td align="right">0.04</td>
</tr>
<tr class="even">
<td>8</td>
<td align="left">Budapest</td>
<td align="right">1.96</td>
<td align="right">17.74</td>
<td align="right">-4.19</td>
<td align="right">-0.24</td>
<td align="right">3.39</td>
<td align="right">0.13</td>
<td align="right">0.99</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="left">BuenosAires</td>
<td align="right">1.96</td>
<td align="right">5.39</td>
<td align="right">-0.89</td>
<td align="right">1.23</td>
<td align="right">0.15</td>
<td align="right">3.43</td>
<td align="right">0.15</td>
<td align="right">0.28</td>
</tr>
<tr class="even">
<td>11</td>
<td align="left">Caracas</td>
<td align="right">1.96</td>
<td align="right">18.07</td>
<td align="right">-4.24</td>
<td align="right">-0.06</td>
<td align="right">3.48</td>
<td align="right">0.01</td>
<td align="right">1.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="left">Chicago</td>
<td align="right">1.96</td>
<td align="right">23.64</td>
<td align="right">4.42</td>
<td align="right">-1.25</td>
<td align="right">3.77</td>
<td align="right">3.55</td>
<td align="right">0.82</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td>13</td>
<td align="left">Copenhagen</td>
<td align="right">1.96</td>
<td align="right">7.43</td>
<td align="right">2.37</td>
<td align="right">-0.83</td>
<td align="right">1.09</td>
<td align="right">1.58</td>
<td align="right">0.76</td>
<td align="right">0.09</td>
</tr>
<tr class="odd">
<td>14</td>
<td align="left">Dublin</td>
<td align="right">1.96</td>
<td align="right">0.79</td>
<td align="right">-0.27</td>
<td align="right">-0.19</td>
<td align="right">0.01</td>
<td align="right">0.08</td>
<td align="right">0.10</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td>15</td>
<td align="left">Dusseldorf</td>
<td align="right">1.96</td>
<td align="right">8.32</td>
<td align="right">2.72</td>
<td align="right">0.24</td>
<td align="right">1.43</td>
<td align="right">0.13</td>
<td align="right">0.89</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>16</td>
<td align="left">Frankfurt</td>
<td align="right">1.96</td>
<td align="right">10.12</td>
<td align="right">3.05</td>
<td align="right">0.63</td>
<td align="right">1.80</td>
<td align="right">0.90</td>
<td align="right">0.92</td>
<td align="right">0.04</td>
</tr>
<tr class="even">
<td>17</td>
<td align="left">Geneva</td>
<td align="right">1.96</td>
<td align="right">42.20</td>
<td align="right">6.36</td>
<td align="right">-0.30</td>
<td align="right">7.82</td>
<td align="right">0.21</td>
<td align="right">0.96</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>18</td>
<td align="left">Helsinki</td>
<td align="right">1.96</td>
<td align="right">0.49</td>
<td align="right">0.03</td>
<td align="right">-0.51</td>
<td align="right">0.00</td>
<td align="right">0.60</td>
<td align="right">0.00</td>
<td align="right">0.53</td>
</tr>
<tr class="even">
<td>19</td>
<td align="left">Hongkong</td>
<td align="right">1.96</td>
<td align="right">3.61</td>
<td align="right">-1.03</td>
<td align="right">0.54</td>
<td align="right">0.21</td>
<td align="right">0.66</td>
<td align="right">0.30</td>
<td align="right">0.08</td>
</tr>
<tr class="odd">
<td>20</td>
<td align="left">Houston</td>
<td align="right">1.96</td>
<td align="right">15.21</td>
<td align="right">3.45</td>
<td align="right">-0.78</td>
<td align="right">2.30</td>
<td align="right">1.37</td>
<td align="right">0.78</td>
<td align="right">0.04</td>
</tr>
<tr class="even">
<td>21</td>
<td align="left">Jakarta</td>
<td align="right">1.96</td>
<td align="right">16.92</td>
<td align="right">-4.08</td>
<td align="right">-0.20</td>
<td align="right">3.22</td>
<td align="right">0.09</td>
<td align="right">0.98</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>22</td>
<td align="left">Johannesburg</td>
<td align="right">1.96</td>
<td align="right">4.88</td>
<td align="right">-2.08</td>
<td align="right">-0.02</td>
<td align="right">0.84</td>
<td align="right">0.00</td>
<td align="right">0.88</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>24</td>
<td align="left">Lagos</td>
<td align="right">1.96</td>
<td align="right">23.54</td>
<td align="right">-4.81</td>
<td align="right">-0.43</td>
<td align="right">4.47</td>
<td align="right">0.42</td>
<td align="right">0.98</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>25</td>
<td align="left">Lisbon</td>
<td align="right">1.96</td>
<td align="right">5.00</td>
<td align="right">-2.17</td>
<td align="right">-0.28</td>
<td align="right">0.91</td>
<td align="right">0.18</td>
<td align="right">0.94</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td>26</td>
<td align="left">London</td>
<td align="right">1.96</td>
<td align="right">0.76</td>
<td align="right">-0.02</td>
<td align="right">-0.63</td>
<td align="right">0.00</td>
<td align="right">0.91</td>
<td align="right">0.00</td>
<td align="right">0.52</td>
</tr>
<tr class="odd">
<td>27</td>
<td align="left">LosAngeles</td>
<td align="right">1.96</td>
<td align="right">18.89</td>
<td align="right">3.64</td>
<td align="right">-1.80</td>
<td align="right">2.57</td>
<td align="right">7.39</td>
<td align="right">0.70</td>
<td align="right">0.17</td>
</tr>
<tr class="even">
<td>28</td>
<td align="left">Luxembourg</td>
<td align="right">1.96</td>
<td align="right">32.79</td>
<td align="right">5.24</td>
<td align="right">0.69</td>
<td align="right">5.30</td>
<td align="right">1.07</td>
<td align="right">0.84</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>29</td>
<td align="left">Madrid</td>
<td align="right">1.96</td>
<td align="right">0.89</td>
<td align="right">-0.06</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>30</td>
<td align="left">Manama</td>
<td align="right">1.96</td>
<td align="right">7.17</td>
<td align="right">-0.82</td>
<td align="right">2.05</td>
<td align="right">0.13</td>
<td align="right">9.60</td>
<td align="right">0.09</td>
<td align="right">0.59</td>
</tr>
<tr class="odd">
<td>31</td>
<td align="left">Manila</td>
<td align="right">1.96</td>
<td align="right">16.51</td>
<td align="right">-4.05</td>
<td align="right">-0.03</td>
<td align="right">3.17</td>
<td align="right">0.00</td>
<td align="right">0.99</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>32</td>
<td align="left">Mexico</td>
<td align="right">1.96</td>
<td align="right">8.63</td>
<td align="right">-2.83</td>
<td align="right">-0.07</td>
<td align="right">1.55</td>
<td align="right">0.01</td>
<td align="right">0.93</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>33</td>
<td align="left">Milan</td>
<td align="right">1.96</td>
<td align="right">0.69</td>
<td align="right">0.02</td>
<td align="right">-0.34</td>
<td align="right">0.00</td>
<td align="right">0.26</td>
<td align="right">0.00</td>
<td align="right">0.17</td>
</tr>
<tr class="even">
<td>34</td>
<td align="left">Montreal</td>
<td align="right">1.96</td>
<td align="right">5.68</td>
<td align="right">2.17</td>
<td align="right">-0.77</td>
<td align="right">0.91</td>
<td align="right">1.34</td>
<td align="right">0.83</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td>35</td>
<td align="left">Nairobi</td>
<td align="right">1.96</td>
<td align="right">23.45</td>
<td align="right">-4.82</td>
<td align="right">-0.26</td>
<td align="right">4.50</td>
<td align="right">0.15</td>
<td align="right">0.99</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>36</td>
<td align="left">NewYork</td>
<td align="right">1.96</td>
<td align="right">23.01</td>
<td align="right">4.60</td>
<td align="right">-0.30</td>
<td align="right">4.09</td>
<td align="right">0.20</td>
<td align="right">0.92</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>37</td>
<td align="left">Nicosia</td>
<td align="right">1.96</td>
<td align="right">3.56</td>
<td align="right">-1.78</td>
<td align="right">-0.27</td>
<td align="right">0.61</td>
<td align="right">0.16</td>
<td align="right">0.89</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td>38</td>
<td align="left">Oslo</td>
<td align="right">1.96</td>
<td align="right">3.98</td>
<td align="right">1.66</td>
<td align="right">-0.73</td>
<td align="right">0.53</td>
<td align="right">1.21</td>
<td align="right">0.69</td>
<td align="right">0.13</td>
</tr>
<tr class="odd">
<td>39</td>
<td align="left">Panama</td>
<td align="right">1.96</td>
<td align="right">5.97</td>
<td align="right">-2.22</td>
<td align="right">0.62</td>
<td align="right">0.96</td>
<td align="right">0.88</td>
<td align="right">0.83</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>40</td>
<td align="left">Paris</td>
<td align="right">1.96</td>
<td align="right">5.31</td>
<td align="right">1.65</td>
<td align="right">1.41</td>
<td align="right">0.53</td>
<td align="right">4.50</td>
<td align="right">0.51</td>
<td align="right">0.37</td>
</tr>
<tr class="odd">
<td>41</td>
<td align="left">Prague</td>
<td align="right">1.96</td>
<td align="right">18.69</td>
<td align="right">-4.29</td>
<td align="right">-0.31</td>
<td align="right">3.56</td>
<td align="right">0.22</td>
<td align="right">0.98</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td>42</td>
<td align="left">RiodeJaneiro</td>
<td align="right">1.96</td>
<td align="right">12.22</td>
<td align="right">-3.40</td>
<td align="right">0.28</td>
<td align="right">2.24</td>
<td align="right">0.18</td>
<td align="right">0.95</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>43</td>
<td align="left">SaoPaulo</td>
<td align="right">1.96</td>
<td align="right">10.33</td>
<td align="right">-3.18</td>
<td align="right">-0.01</td>
<td align="right">1.96</td>
<td align="right">0.00</td>
<td align="right">0.98</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>44</td>
<td align="left">Seoul</td>
<td align="right">1.96</td>
<td align="right">0.69</td>
<td align="right">-0.61</td>
<td align="right">-0.04</td>
<td align="right">0.07</td>
<td align="right">0.00</td>
<td align="right">0.54</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>45</td>
<td align="left">Singapore</td>
<td align="right">1.96</td>
<td align="right">2.64</td>
<td align="right">-1.16</td>
<td align="right">-0.16</td>
<td align="right">0.26</td>
<td align="right">0.06</td>
<td align="right">0.51</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td>46</td>
<td align="left">Stockholm</td>
<td align="right">1.96</td>
<td align="right">2.16</td>
<td align="right">0.67</td>
<td align="right">-0.98</td>
<td align="right">0.09</td>
<td align="right">2.20</td>
<td align="right">0.21</td>
<td align="right">0.45</td>
</tr>
<tr class="odd">
<td>47</td>
<td align="left">Sidney</td>
<td align="right">1.96</td>
<td align="right">0.62</td>
<td align="right">0.03</td>
<td align="right">-0.21</td>
<td align="right">0.00</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td>48</td>
<td align="left">Taipei</td>
<td align="right">1.96</td>
<td align="right">6.07</td>
<td align="right">1.64</td>
<td align="right">-0.27</td>
<td align="right">0.52</td>
<td align="right">0.17</td>
<td align="right">0.45</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>49</td>
<td align="left">Tel-Aviv</td>
<td align="right">1.96</td>
<td align="right">3.35</td>
<td align="right">-1.41</td>
<td align="right">0.00</td>
<td align="right">0.38</td>
<td align="right">0.00</td>
<td align="right">0.59</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>50</td>
<td align="left">Tokyo</td>
<td align="right">1.96</td>
<td align="right">46.73</td>
<td align="right">6.72</td>
<td align="right">0.72</td>
<td align="right">8.72</td>
<td align="right">1.18</td>
<td align="right">0.97</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>51</td>
<td align="left">Toronto</td>
<td align="right">1.96</td>
<td align="right">4.86</td>
<td align="right">1.77</td>
<td align="right">-1.06</td>
<td align="right">0.60</td>
<td align="right">2.53</td>
<td align="right">0.64</td>
<td align="right">0.23</td>
</tr>
<tr class="even">
<td>52</td>
<td align="left">Vienna</td>
<td align="right">1.96</td>
<td align="right">4.07</td>
<td align="right">1.86</td>
<td align="right">-0.11</td>
<td align="right">0.67</td>
<td align="right">0.03</td>
<td align="right">0.85</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>53</td>
<td align="left">Zurich</td>
<td align="right">1.96</td>
<td align="right">65.45</td>
<td align="right">7.90</td>
<td align="right">0.29</td>
<td align="right">12.08</td>
<td align="right">0.20</td>
<td align="right">0.95</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>The column <code>wgt</code> indicates the weight of each city, which in this case is a uniform weight of 100 / 51 = 1.96.</p>
<p>The column <code>disto</code> provides the squared distance of each city to the center of gravity. This column allows us to find which cities are the <em>typical</em> cities (i.e. the closest ones to the center of gravity), such as Helsinki. Likewise, it allows us to identify the <em>unusual</em> or <em>unique</em> cities (i.e. those that have a large distance to the center of gravity) like Zurich or Tokyo. In general, the distance to the center of gravity is a criterion of the <em>singularity</em> of each city.</p>
<p>The third and fourth columns correspond to the coordinates obtained from projecting the cities onto the first two factorial axes. The representation on the first factorial plane is obtained with these coordinateas (<span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span>), given in figure <a href="basic.html#fig:fig-1-9">1.9</a>.</p>
<p>It is important to mention that the orientation of a factorial axis is arbitrary: the important trait is the direction. We could change the orientation of an axis by changing the sign of the coordinates on this axis. Graphically, this means that all symmetries are possible. The user has to make the decision of which orientation is the most convenient.</p>
</div>
<div id="interpretation-tools" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Interpretation Tools</h3>
<div id="contributions" class="section level4 unnumbered">
<h4>Contributions</h4>
<p>The next two columns, <code>contr1</code> and <code>contr2</code>, provide the <em>contributions</em> (in percentages) of the cities to the explained inertia by each axis. The inertia of an axis is obtained via formula <a href="mechanics.html#eq:2-2">(2.2)</a>. Thus, we can measure the part of an axis’ inertia that is due to a given row-point by means of the quotient:</p>
<p><span class="math display" id="eq:2-4">\[
CTR(i, \alpha) = \frac{p_i \psi^{2}_{i \alpha}}{\lambda_{\alpha}} \times 100
\tag{2.4}
\]</span></p>
<p>The above quotient is the contribution of a point <span class="math inline">\(i\)</span> to the construction of axis <span class="math inline">\(\alpha\)</span>.</p>
<p>We can use the contributions to identify the cities that contribute the most to the construction of the factorial axes.</p>
<p>If all cities had the same contribution, this would have a value of about 2% (100/51). Consequently, all those cities with contributions greater than 2% can be considered to have influence above the average.</p>
<p><em>When is a contribution considered to be “high”?</em></p>
<p>The answer to this question is not straightforward. A contribution will be considered “high” when, compared to the rest of contributions, it has an unusual large value.</p>
<p>For example, the city that contributes the most to the second axis is Abu Dhabi (48%). Almost half of the inertia of this axis is due to this city alone. Abu Dhabi is clearly very influent in the construction of this axis. We can actually ask about the stability of this axis, meaning, how much the result would change if Abu Dhabi were to be eliminated?</p>
<p>The next figure <a href="mechanics.html#fig:fig-2-3">2.3</a> shows the cities with a size proportional to their contributions on the first factorial plane (sum of the contributions of the first two axes).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-3"></span>
<img src="images/figure-2-3.png" alt="Contributions of the cities in the first factorial plane" width="80%" />
<p class="caption">
Figure 2.3: Contributions of the cities in the first factorial plane
</p>
</div>
<p>All the active points play a role in the construction of an axis. We can check that the sum of all the contributions in an axis add up to 100.</p>
<p><span class="math display" id="eq:2-5">\[
\sum_{i=1}^{n} CTR(i, \alpha) = 100
\tag{2.5}
\]</span></p>
</div>
<div id="squared-cosines" class="section level4 unnumbered">
<h4>Squared Cosines</h4>
<p>The last columns of the table of results, <code>cosqr1</code> and <code>cosqr2</code>, contain the values of the <strong>squared cosines</strong>. These are used to assess the quality of the obtained factorial configuration when compared to the original configuration of the row-points.</p>
<p>Because the obtained representations are an approximation of the real distances between points, it is expected that some distances between pairs of points will be better represented whereas other distances will not reliably reflect the real distance between two points.</p>
<p>The goal is to have a good idea of how close is a point with respect to the factorial plane. If two points are close to the factorial plane, then the projected distance will be a good approximation to the actual distance in the original space. However, if at least one point is further away from the projection plane, then the real distance can be very different from that represented in the factorial plane.</p>
<p>This proximity to the factorial plane is measured with the squared cosine of each point to the factorial axes.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-4"></span>
<img src="images/figure-2-4.png" alt="The squared cosine as a measure of proximity" width="60%" />
<p class="caption">
Figure 2.4: The squared cosine as a measure of proximity
</p>
</div>
<p>The figure <a href="mechanics.html#fig:fig-2-4">2.4</a> illustrates the definition given in equation <a href="mechanics.html#eq:2-6">(2.6)</a></p>
<p><span class="math display" id="eq:2-6">\[
COS^2(i, \alpha) = \frac{\psi^{2}_{i \alpha}}{d^2(i, G)}
\tag{2.6}
\]</span></p>
<p>A squared cosine of means that the city is on the factorial axis (i.e. the angle <span class="math inline">\(\omega\)</span> is zero), whereas a squared cosine of 0 indicates that the city is on an orthogonal direction to the axis.</p>
<p>Notice that the sum of the squared cosines over all <span class="math inline">\(p\)</span> factorial axes is equal to 1. This has to do with fact that all axes are needed in order to have the exact position of a point in the entire space.</p>
<p><span class="math display" id="eq:2-7">\[
\sum_{\alpha = 1}^{p} COS^2(i, \alpha) = 1
\tag{2.7}
\]</span></p>
<p>Interestingly, the sum of the squared cosines of a given point over the first axes provides, in percentage, the “quality” of representation of the point in the subspace defined by these axes.</p>
<p><em>What value of a squared cosine indicates that a point is “well represented” on a factorial plane?</em></p>
<p>Similar to the contributions, the answer to the above question is not straightforward. A squared cosine (or the sum on the first two axes of the factorial plane) has to be compared with the rest of the squared cosines in order to determine if it is large or small.</p>
<p>In our working example, the cities are in general well represented on the first factorial plane. The sum of the squared cosines over the first two axes is close to 1. However, cities such as Dublin, Madrid, Sidney or Milan, which are close to the center, are not well represented. In contrast, Mumbai or Caracas are perfectly represented. Figure <a href="mechanics.html#fig:fig-2-5">2.5</a> shows the cities with a size proportional to their squared cosine on the first factorial plane.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-5"></span>
<img src="images/figure-2-5.png" alt="Squared cosines of the cities on the first factorial plane" width="80%" />
<p class="caption">
Figure 2.5: Squared cosines of the cities on the first factorial plane
</p>
</div>
<p>The cities that are deficiently represented in this plane are the “average” cities. We can only interpret the proximity between cities if they are well represented on the factorial plane.</p>
</div>
</div>
</div>
<div id="projections-of-variables" class="section level2">
<h2><span class="header-section-number">2.2</span> Projections of Variables</h2>
<p>Just like row-points can be represented on a low-dimensional factorial space that preserves as much as possible the original distances, we can do the same with the column-points (i.e. the variables).</p>
<p>Mathematically, working with the column-points implies diagonalizing the cross-product matrix <span class="math inline">\(\mathbf{X X^\mathsf{T}}\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-6"></span>
<img src="images/figure-2-6.png" alt="Matrices to be diagonalized depending on the type of points" width="75%" />
<p class="caption">
Figure 2.6: Matrices to be diagonalized depending on the type of points
</p>
</div>
<p>Analogously to the row-points, we can obtain the decomposition of the inertia depending on the directions defined by the eigenvalues of the matrix <span class="math inline">\(\mathbf{X X^\mathsf{T}}\)</span>. The projected inertia on each direction is equal to its associated eigenvalue.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-7"></span>
<img src="images/figure-2-7.png" alt="Cloud of variables and factorial axes in the space of individuals" width="70%" />
<p class="caption">
Figure 2.7: Cloud of variables and factorial axes in the space of individuals
</p>
</div>
<p>The line of maximum inertia is given by the eigenvector <span class="math inline">\(\mathbf{v}\)</span> (defining the direction <span class="math inline">\(F_1\)</span>), associated to the largest eigenvalue. The plane of maximum inertia is formed by adding the line that defines the direction <span class="math inline">\(F_2\)</span>. This second direction corresponds to the eigenvector associated to the second largest eigenvalue, and so on.</p>
<p>The representation of the variables on an axis is obtained by projecting the variable-points onto a unit vector <span class="math inline">\(\mathbf{v}\)</span> that defines the direction of the axis.</p>
<p>Let <span class="math inline">\(\varphi_{j \alpha}\)</span> be the coordinate of the <span class="math inline">\(j\)</span> variable on the axis <span class="math inline">\(\alpha\)</span></p>
<p><span class="math display" id="eq:2-8">\[
\varphi_{j \alpha} = \sum_{i=1}^{n} \frac{x_{ij} - \bar{x}_j}{s_j} \hspace{1mm} v_{i \alpha}
\tag{2.8}
\]</span></p>
<p>where <span class="math inline">\(\bar{x}_j\)</span> is the mean of the <span class="math inline">\(j\)</span>-th variable.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-8"></span>
<img src="images/figure-2-8.png" alt="Projection of the variables on the first factorial plane" width="85%" />
<p class="caption">
Figure 2.8: Projection of the variables on the first factorial plane
</p>
</div>
<p>The inertia on an axis is given by the sum of the inertias of each variable-point projected onto the axis. In PCA there is not an explicit weight for the variable-points. However, each variable can play a role more or less important by changing the unit of measurement, which in turn will increase (or decrease) its variance in a non-normalized PCA.</p>
<p><span class="math display" id="eq:2-9">\[
\sum_{j=1}^{p} \varphi^{2}_{j \alpha} = \lambda_{\alpha}
\tag{2.9}
\]</span></p>
<p>Notice that the inertia of the variable-points that are projected onto an axis is the same as the inertia of the row-points projected on the axis of same rank.</p>
<p>Among the factorial axes of both clouds of points, the factorial axes in one space are related to the factorial axes in the other space. Thiese relationships allow us to obtain the directions of one space taking into account the directions of the other space. Such relationships are known as <em>transition relationships</em>.</p>
<p>By using the transition relationships, we just need to perform a PCA on one of the spaces (e.g. the rows), and then use these results to derive the results of the other space (e.g. the columns), without having to diagonalize two different cross-products.</p>
<p>In general, we perform the analysis on the cross-product with the smaller dimensions. Usually, this involves working with the matrix <span class="math inline">\(\mathbf{X^\mathsf{T} X}\)</span>, assuming that the data matrix has more rows than columns: <span class="math inline">\(n &gt; p\)</span>. In this scenario, we obtain the projection of the row-points given in equation <a href="mechanics.html#eq:2-1">(2.1)</a>. The projection of the variables is then calculated from the directions <span class="math inline">\(\mathbf{u}\)</span>, which define the factorial axes of the cloud of row-points.</p>
<p><span class="math display" id="eq:2-10">\[
\varphi_{j \alpha} = \sqrt{\lambda_{\alpha}} \hspace{1mm} u_{j \alpha}
\tag{2.10}
\]</span></p>
<p>The above formula allows us to interpret the simultaneous representation of both the cities and the professions.</p>
<p>In our working example, the results about the variables are displayed in table 2.3</p>
<table>
<caption><span id="tab:table-2-3">Table 2.3: </span>Results of the variables</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">coord1</th>
<th align="right">coord2</th>
<th align="right">coord3</th>
<th align="right">cor1</th>
<th align="right">cor2</th>
<th align="right">cor3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>teacher</td>
<td align="right">0.94</td>
<td align="right">-0.04</td>
<td align="right">-0.21</td>
<td align="right">0.94</td>
<td align="right">-0.04</td>
<td align="right">-0.21</td>
</tr>
<tr class="even">
<td>bus_driver</td>
<td align="right">0.96</td>
<td align="right">-0.13</td>
<td align="right">-0.15</td>
<td align="right">0.96</td>
<td align="right">-0.13</td>
<td align="right">-0.15</td>
</tr>
<tr class="odd">
<td>mechanic</td>
<td align="right">0.92</td>
<td align="right">-0.27</td>
<td align="right">0.19</td>
<td align="right">0.92</td>
<td align="right">-0.27</td>
<td align="right">0.19</td>
</tr>
<tr class="even">
<td>construction_worker</td>
<td align="right">0.90</td>
<td align="right">-0.37</td>
<td align="right">0.11</td>
<td align="right">0.90</td>
<td align="right">-0.37</td>
<td align="right">0.11</td>
</tr>
<tr class="odd">
<td>metalworker</td>
<td align="right">0.95</td>
<td align="right">-0.24</td>
<td align="right">-0.02</td>
<td align="right">0.95</td>
<td align="right">-0.24</td>
<td align="right">-0.02</td>
</tr>
<tr class="even">
<td>cook_chef</td>
<td align="right">0.87</td>
<td align="right">0.24</td>
<td align="right">0.40</td>
<td align="right">0.87</td>
<td align="right">0.24</td>
<td align="right">0.40</td>
</tr>
<tr class="odd">
<td>factory_manager</td>
<td align="right">0.84</td>
<td align="right">0.49</td>
<td align="right">-0.01</td>
<td align="right">0.84</td>
<td align="right">0.49</td>
<td align="right">-0.01</td>
</tr>
<tr class="even">
<td>engineer</td>
<td align="right">0.90</td>
<td align="right">0.27</td>
<td align="right">-0.03</td>
<td align="right">0.90</td>
<td align="right">0.27</td>
<td align="right">-0.03</td>
</tr>
<tr class="odd">
<td>bank_clerk</td>
<td align="right">0.88</td>
<td align="right">0.38</td>
<td align="right">-0.13</td>
<td align="right">0.88</td>
<td align="right">0.38</td>
<td align="right">-0.13</td>
</tr>
<tr class="even">
<td>executive_secretary</td>
<td align="right">0.97</td>
<td align="right">0.00</td>
<td align="right">-0.10</td>
<td align="right">0.97</td>
<td align="right">0.00</td>
<td align="right">-0.10</td>
</tr>
<tr class="odd">
<td>salesperson</td>
<td align="right">0.96</td>
<td align="right">0.01</td>
<td align="right">0.08</td>
<td align="right">0.96</td>
<td align="right">0.01</td>
<td align="right">0.08</td>
</tr>
<tr class="even">
<td>textile_worker</td>
<td align="right">0.94</td>
<td align="right">-0.25</td>
<td align="right">-0.10</td>
<td align="right">0.94</td>
<td align="right">-0.25</td>
<td align="right">-0.10</td>
</tr>
</tbody>
</table>
<p>The coordinates of all the variables in the first axis have the same sign, which indicates that the cloud of points is not centered.</p>
<p>Notice also that, in the case of normalized analysis, the coordinate coincides with the correlation of a variable and the principal component (projection of the points onto the factorial axis of same rank):</p>
<p><span class="math display" id="eq:2-11">\[
\varphi_{j \alpha} = cor(\mathbf{x_j}, \boldsymbol{\psi_{\alpha}})
\tag{2.11}
\]</span></p>
<p>This formula plays an important role in the interpretation of the results because it connects the representation of the row-points with the representation of the column-points.</p>
<p>A high correlation implies that the configuration of the individuals on a factorial axis resembles the positions of the individuals on that variable (a unit correlation would indicate that the principal component is a linear function of the variable). A correlation close to zero indicates that there is no <em>linear</em> association between the principal component and the variable.</p>
<div id="size-effect" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Size Effect</h3>
<p>As we’ve described it, the first principal component arises from the high correlation that exists among all the variables, which geometrically forms a very homogeneous array of vectors. This first component approximately corresponds to the bisector of this array of vectors, and will therefore be highly correlated to the original variables.</p>
<p>How can we interpret this phenomenon? Broadly speaking, for any city, if a salary is high in a given profession, then this is also true for the set of professions in that city. This general phenomenon is actually present in the entire data table as a structural pattern, which generates the first factor. And it is for this reason that we call the first component the <strong>size factor</strong> or <strong>size effect</strong>.</p>
<table>
<caption><span id="tab:table-2-4">Table 2.4: </span>Correlation matrix ordered based on the size factor</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">exe</th>
<th align="right">sal</th>
<th align="right">bus</th>
<th align="right">met</th>
<th align="right">tea</th>
<th align="right">tex</th>
<th align="right">mec</th>
<th align="right">eng</th>
<th align="right">con</th>
<th align="right">ban</th>
<th align="right">coo</th>
<th align="right">dep</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>exe</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>sal</td>
<td align="right">0.94</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>bus</td>
<td align="right">0.93</td>
<td align="right">0.89</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>met</td>
<td align="right">0.92</td>
<td align="right">0.88</td>
<td align="right">0.94</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>tea</td>
<td align="right">0.92</td>
<td align="right">0.88</td>
<td align="right">0.96</td>
<td align="right">0.91</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>tex</td>
<td align="right">0.93</td>
<td align="right">0.89</td>
<td align="right">0.92</td>
<td align="right">0.94</td>
<td align="right">0.88</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>mec</td>
<td align="right">0.88</td>
<td align="right">0.89</td>
<td align="right">0.89</td>
<td align="right">0.93</td>
<td align="right">0.84</td>
<td align="right">0.89</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>eng</td>
<td align="right">0.87</td>
<td align="right">0.85</td>
<td align="right">0.82</td>
<td align="right">0.80</td>
<td align="right">0.81</td>
<td align="right">0.81</td>
<td align="right">0.74</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>con</td>
<td align="right">0.86</td>
<td align="right">0.86</td>
<td align="right">0.88</td>
<td align="right">0.93</td>
<td align="right">0.83</td>
<td align="right">0.92</td>
<td align="right">0.95</td>
<td align="right">0.70</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>ban</td>
<td align="right">0.87</td>
<td align="right">0.85</td>
<td align="right">0.80</td>
<td align="right">0.72</td>
<td align="right">0.82</td>
<td align="right">0.73</td>
<td align="right">0.70</td>
<td align="right">0.85</td>
<td align="right">0.64</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>coo</td>
<td align="right">0.80</td>
<td align="right">0.85</td>
<td align="right">0.76</td>
<td align="right">0.76</td>
<td align="right">0.75</td>
<td align="right">0.71</td>
<td align="right">0.80</td>
<td align="right">0.82</td>
<td align="right">0.72</td>
<td align="right">0.79</td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>dep</td>
<td align="right">0.80</td>
<td align="right">0.79</td>
<td align="right">0.74</td>
<td align="right">0.69</td>
<td align="right">0.78</td>
<td align="right">0.65</td>
<td align="right">0.64</td>
<td align="right">0.87</td>
<td align="right">0.59</td>
<td align="right">0.89</td>
<td align="right">0.82</td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>Having a first principal component that captures the <em>size effect</em> is a common phenomenon in PCA. A distinctive trait is that the matrix of correlations between the variables can be arranged based on the correlations with the first principal component. As we can tell from table 2.4, there are high correlations close to the diagonal, and then they decrease as one moves away from this diagonal.</p>
<div id="interpretation-of-the-axes" class="section level4 unnumbered">
<h4>Interpretation of the Axes</h4>
<p>To better interpret a factorial axis we should take into account the variables that have a relative high correlation with the axis.</p>
<p>We have seen that the first axis is interpreted as a factor of size: differentiating cities according to their overall salary levels. The subsequent principal components comprise factors that are orthogonal to the first one.</p>
<p>The first principal component (projection of the cities onto the first direction of the cloud of row-points) provides an ordination of the cities depending on their salary levels. This first component opposes Swiss cities (Zurich and Geneva) and Tokyo to cities like Mumbai, Manila and Nairobi.</p>
<p>The second factorial axis, showing lower correlations with the original variables, opposes the professions <code>factory_manager</code>, <code>engineer</code>, <code>bank_clerk</code>, and <code>cook_chef</code> to <code>textile_worker</code>, <code>construction_worker</code>, <code>mechanic</code>, and <code>metalworker</code>. In other words, the second axis has to do with the fact that, independently from the salaries of a city, certain professions have a higher salaries than others.</p>
<p>The projection onto the second axis allows to distinguish cities with similar overall level of salaries: certain cities tend to value the <em>managerial</em> jobs, whereas other cities tend to value the professions less socially appreciated.</p>
</div>
</div>
<div id="tools-for-interpreting-components" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Tools for Interpreting Components</h3>
<div id="cosine-squares" class="section level4 unnumbered">
<h4>Cosine Squares</h4>
<p>In a similar fashion to the analysis of the individuals (i.e. the cities), we can also define a set of coefficients, squared cosines, and contributions, that will help us in the interpretation of results in the analysis of the variables.</p>
<p>The squared cosines are defined as the quotient between the projected squared distance on an axis and the squared distance to the origin.</p>
<p>We know that the squared distance of a variable to the origin is equal to its variance:</p>
<p><span class="math display" id="eq:2-12">\[
COS^2(j, \alpha) = \frac{\varphi^{2}_{j \alpha}}{var(j)}
\tag{2.12}
\]</span></p>
<p>The sum of the squared cosines over all the axes is always equal to one:</p>
<p><span class="math display" id="eq:2-13">\[
\sum_{\alpha = 1}^{p} COS^2(j, \alpha) = 1
\tag{2.13}
\]</span></p>
<p>In the normalized PCA, the variances are equal to one; thus the squared cosines will be squared of the coordinates of the variables:</p>
<p><span class="math display">\[
COS^2(j, \alpha) = \varphi_{j \alpha}^{2} \qquad \text{in normalized PCA}
\]</span></p>
<p>In general, we have that:</p>
<p><span class="math display">\[
COS^2(j, \alpha) = CORR^2(\text{variable}, \text{factor})
\]</span></p>
</div>
<div id="contributions-1" class="section level4 unnumbered">
<h4>Contributions</h4>
<p>The contribution of each variable to the inertia of an axis is the part of the inertia accounted for the variable. The inertia of an axis (see eq <a href="mechanics.html#eq:2-9">(2.9)</a>) is expressed as:</p>
<p><span class="math display">\[
\lambda_{\alpha} = \sum_{j=1}^{p} \varphi_{j \alpha}^{2}
\]</span></p>
<p>The contribution of a variable to the construction of an axis is:</p>
<p><span class="math display" id="eq:2-14">\[
CTR(j, \alpha) = \frac{\varphi_{j \alpha}^{2}}{\lambda_{\alpha}} = \frac{(\sqrt{\lambda_{\alpha}} \hspace{1mm} u_{j \alpha})^2}{\lambda_{\alpha}} = u_{j \alpha}^{2}
\tag{2.14}
\]</span></p>
<p>where <span class="math inline">\(u_{j \alpha}^{2}\)</span> is the coordinate of the former unit axis associated to the variable <span class="math inline">\(j\)</span>, projected on the axis <span class="math inline">\(\alpha\)</span>.</p>
<p>We have the following result:</p>
<p><span class="math display">\[
CTR(j, \alpha) = (\text{former unit axis})^2
\]</span></p>
<p>To find how much a variable contributes to the construction of an axis, it suffices to square each component of the vector <span class="math inline">\(\mathbf{u}\)</span>. These contributions indicate which variables are responsible for the construction of each axis. The sum of all the contributions to an axis is equal to 1 (or 100 in percentage).</p>
<p><span class="math display" id="eq:2-15">\[
\sum_{j=1}^{p} CTR(j, \alpha) = 100
\tag{2.15}
\]</span></p>
<p>The elements of <span class="math inline">\(\mathbf{u}\)</span> define the linear combinations of the original variables, orthogonal among each other, and of maximum variance (i.e. the principal components). For example, the linear combination of the first component is:</p>
<p><span class="math display">\[
\boldsymbol{\psi_1} = 0.30 \texttt{ teacher} + 0.30 \texttt{ bus_driver} + 0.29 \texttt{ mechanic} \\
+ 0.28 \texttt{ construction_worker} + 0.30 \texttt{ metalworker} + 0.27 \texttt{ cook_chef} + \\
+0.26 \texttt{ factory_manager} + 0.28 \texttt{ engineer} + 0.28 \texttt{ bank_clerk} + \\
+ 0.31 \texttt{ executive_secretary} + 0.30 \texttt{ salesperson} + 0.29 \texttt{ textile_worker}
\]</span></p>
<p>where each variable has been mean-centered and standardized (because we have performed a normalized PCA).</p>
<p>The first component is therefore defined by a set of coefficients, very similar to each other. In this particular case, the first component is not that different from the average of all the profession salaries.</p>
<p>The set of components <span class="math inline">\(u_{j \alpha}\)</span> also define the projection of the former unit axes onto the new factorial axes.</p>
</div>
</div>
</div>
<div id="size-factor" class="section level2">
<h2><span class="header-section-number">2.3</span> Beyond the First Factor</h2>
<p>The most striking fact from the results discussed so far is the so-called <em>size factor</em> (or size effect) which is extremely dominant in our working example. This size factor, reflected in the first principal component, exclusively shows the salary inequality among the cities. The rest of the factors are somewhat “squeezed” by the strength of this phenomenon in the data table.</p>
<p>When a size factor dominates the analysis, it is interesting to rerun a Principal Component Analysis but controlling (eliminating) for the size effect. This involves taking into account the previous knowledge about the salaries in the cities in order to go beyond their salary inequality.</p>
<p>A simple way to achieve this consists of dividing the salaries of each profession by the mean salary in each city, thus eliminating the aforementioned effect of salary inequality. The mean salary of a city can be obtained as the average of the salaries in that city. However, we have decided to obtain the mean salaries of cities in a slightly different form: as the product of the <em>net hourly salary</em> times the <em>number of hours worked per year</em> (i.e. the product of columns <code>net_hourly_salary</code> and <code>work_hours_year</code>).</p>
<p>At the same time, we have decided to create two new artificial variables (for illustrative purposes). One indicates the “salary inequality” of each city: as the difference between its higher salary and its lower salary, with respect to mean salary of the city:</p>
<p><span class="math display">\[
\text{salary inequality} = \frac{\text{salary}_{max} - \text{salary}_{min}}{\text{mean salary of the city}}
\]</span></p>
<p>Another variable about the salary of the manual jobs with a certain qualification, is obtained as the mean salary of <code>mechanic</code> and <code>metalworker</code>:</p>
<p><span class="math display">\[
\text{qualified manual jobs} = \frac{\texttt{mechanic} + \texttt{metalworker}}{2 \times \text{mean salary of the city}}
\]</span></p>
<p>The new data table contains 12 new variables of salaries (quotient between the salary of a profession relative to the mean salary of the city). We can then perform a Principal Component Analysis on this new table. The table 2.5 contains the summary statistics of these new 12 active variables:</p>
<table>
<caption><span id="tab:table-2-5">Table 2.5: </span>Summary Statistics of the second analysis</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">weight</th>
<th align="right">mean</th>
<th align="right">stdev</th>
<th align="right">min</th>
<th align="right">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>teacher2</td>
<td align="right">51</td>
<td align="right">1.19</td>
<td align="right">0.37</td>
<td align="right">0.37</td>
<td align="right">2.07</td>
</tr>
<tr class="even">
<td>bus_driver2</td>
<td align="right">51</td>
<td align="right">1.04</td>
<td align="right">0.25</td>
<td align="right">0.46</td>
<td align="right">1.69</td>
</tr>
<tr class="odd">
<td>mechanic2</td>
<td align="right">51</td>
<td align="right">0.96</td>
<td align="right">0.24</td>
<td align="right">0.14</td>
<td align="right">1.47</td>
</tr>
<tr class="even">
<td>construction_worker2</td>
<td align="right">51</td>
<td align="right">0.72</td>
<td align="right">0.27</td>
<td align="right">0.13</td>
<td align="right">1.17</td>
</tr>
<tr class="odd">
<td>metalworker2</td>
<td align="right">51</td>
<td align="right">1.17</td>
<td align="right">0.22</td>
<td align="right">0.50</td>
<td align="right">1.88</td>
</tr>
<tr class="even">
<td>cook_chef2</td>
<td align="right">51</td>
<td align="right">1.40</td>
<td align="right">0.62</td>
<td align="right">0.48</td>
<td align="right">3.50</td>
</tr>
<tr class="odd">
<td>factory_manager2</td>
<td align="right">51</td>
<td align="right">2.63</td>
<td align="right">1.32</td>
<td align="right">1.37</td>
<td align="right">6.96</td>
</tr>
<tr class="even">
<td>engineer2</td>
<td align="right">51</td>
<td align="right">2.12</td>
<td align="right">0.76</td>
<td align="right">1.14</td>
<td align="right">4.37</td>
</tr>
<tr class="odd">
<td>bank_clerk2</td>
<td align="right">51</td>
<td align="right">1.51</td>
<td align="right">0.62</td>
<td align="right">0.77</td>
<td align="right">3.50</td>
</tr>
<tr class="even">
<td>executive_secretary2</td>
<td align="right">51</td>
<td align="right">1.13</td>
<td align="right">0.28</td>
<td align="right">0.76</td>
<td align="right">2.07</td>
</tr>
<tr class="odd">
<td>salesperson2</td>
<td align="right">51</td>
<td align="right">0.76</td>
<td align="right">0.16</td>
<td align="right">0.37</td>
<td align="right">1.13</td>
</tr>
<tr class="even">
<td>textile_worker2</td>
<td align="right">51</td>
<td align="right">0.68</td>
<td align="right">0.18</td>
<td align="right">0.22</td>
<td align="right">1.09</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>We can see that the best paid profession is <code>factory_manager</code> which, in average, is two and half times above the mean salary. In contrast, the worst paid profession if <code>textile_worker</code> with a salary of 2/3 the mean salary.</p>
<p>When looking at the matrix of correlations (see table <a href="mechanics.html#tab:table-2-6">2.6</a>) we now have values that are very different from table <a href="basic.html#tab:table-1-3">1.1</a>. These new correlations are actually partial correlations, because we have removed the effect that is due to the salary level per city.</p>
<table>
<caption><span id="tab:table-2-6">Table 2.6: </span>Correlations</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">tea2</th>
<th align="right">bus2</th>
<th align="right">mec2</th>
<th align="right">con2</th>
<th align="right">met2</th>
<th align="right">coo2</th>
<th align="right">dep2</th>
<th align="right">eng2</th>
<th align="right">ban2</th>
<th align="right">exe2</th>
<th align="right">sal2</th>
<th align="right">tex2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>tea2</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>bus2</td>
<td align="right">0.38</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>mec2</td>
<td align="right">-0.33</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>con2</td>
<td align="right">0.24</td>
<td align="right">0.34</td>
<td align="right">0.31</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>met2</td>
<td align="right">0.06</td>
<td align="right">0.14</td>
<td align="right">0.15</td>
<td align="right">0.08</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>coo2</td>
<td align="right">-0.12</td>
<td align="right">-0.42</td>
<td align="right">-0.26</td>
<td align="right">-0.51</td>
<td align="right">-0.38</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>dep2</td>
<td align="right">-0.12</td>
<td align="right">-0.24</td>
<td align="right">-0.41</td>
<td align="right">-0.63</td>
<td align="right">-0.19</td>
<td align="right">0.37</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>eng2</td>
<td align="right">-0.15</td>
<td align="right">-0.40</td>
<td align="right">-0.35</td>
<td align="right">-0.72</td>
<td align="right">-0.16</td>
<td align="right">0.52</td>
<td align="right">0.57</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>ban2</td>
<td align="right">-0.08</td>
<td align="right">-0.16</td>
<td align="right">-0.38</td>
<td align="right">-0.37</td>
<td align="right">-0.51</td>
<td align="right">0.32</td>
<td align="right">0.59</td>
<td align="right">0.38</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="even">
<td>exe2</td>
<td align="right">-0.39</td>
<td align="right">-0.50</td>
<td align="right">-0.37</td>
<td align="right">-0.62</td>
<td align="right">-0.33</td>
<td align="right">0.48</td>
<td align="right">0.38</td>
<td align="right">0.54</td>
<td align="right">0.42</td>
<td align="right">1.00</td>
<td align="right"></td>
<td align="right"></td>
</tr>
<tr class="odd">
<td>sal2</td>
<td align="right">-0.02</td>
<td align="right">-0.07</td>
<td align="right">-0.09</td>
<td align="right">-0.16</td>
<td align="right">-0.36</td>
<td align="right">-0.03</td>
<td align="right">0.06</td>
<td align="right">0.19</td>
<td align="right">0.10</td>
<td align="right">0.12</td>
<td align="right">1.00</td>
<td align="right"></td>
</tr>
<tr class="even">
<td>tex2</td>
<td align="right">0.25</td>
<td align="right">0.38</td>
<td align="right">-0.14</td>
<td align="right">0.41</td>
<td align="right">0.06</td>
<td align="right">-0.51</td>
<td align="right">-0.48</td>
<td align="right">-0.31</td>
<td align="right">-0.35</td>
<td align="right">-0.26</td>
<td align="right">0.05</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Observe that we now have negative correlations, indicating that when a profession is well paid in a given city, it is detrimental to other profession (values below 0.28 in absolute value, indicate correlations non-significantly different from zero).</p>
<p>The diagonalization of the correlation matrix provides the eigenvalues displayed in table <a href="mechanics.html#tab:table-2-7">2.7</a>:</p>
<table>
<caption><span id="tab:table-2-7">Table 2.7: </span>Distribution of eigenvalues.</caption>
<thead>
<tr class="header">
<th align="right">num</th>
<th align="right">eigenvalues</th>
<th align="right">percentage</th>
<th align="right">cumulative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">4.4910</td>
<td align="right">37.43</td>
<td align="right">37.43</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1.7148</td>
<td align="right">14.29</td>
<td align="right">51.72</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1.2989</td>
<td align="right">10.82</td>
<td align="right">62.54</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1.0396</td>
<td align="right">8.66</td>
<td align="right">71.20</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.8699</td>
<td align="right">7.25</td>
<td align="right">78.45</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.7831</td>
<td align="right">6.53</td>
<td align="right">84.98</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.5309</td>
<td align="right">4.42</td>
<td align="right">89.40</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.3874</td>
<td align="right">3.23</td>
<td align="right">92.63</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.3210</td>
<td align="right">2.67</td>
<td align="right">95.31</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.2561</td>
<td align="right">2.13</td>
<td align="right">97.44</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="right">0.2021</td>
<td align="right">1.68</td>
<td align="right">99.12</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">0.1052</td>
<td align="right">0.88</td>
<td align="right">100.00</td>
</tr>
</tbody>
</table>
<p><img src="_main_files/figure-html/unnamed-chunk-7-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The projection of the new (transformed) variables on the three axes obtained in the second analysis, are contained in the table <a href="mechanics.html#tab:table-2-8">2.8</a> shown below</p>
<table>
<caption><span id="tab:table-2-8">Table 2.8: </span>Results for the variables in the second analysis</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">coord1</th>
<th align="right">coord2</th>
<th align="right">coord3</th>
<th align="right">cor1</th>
<th align="right">cor2</th>
<th align="right">cor3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>teacher2</td>
<td align="right">-0.31</td>
<td align="right">0.69</td>
<td align="right">0.30</td>
<td align="right">-0.31</td>
<td align="right">0.69</td>
<td align="right">0.30</td>
</tr>
<tr class="even">
<td>bus_driver2</td>
<td align="right">-0.56</td>
<td align="right">0.47</td>
<td align="right">0.13</td>
<td align="right">-0.56</td>
<td align="right">0.47</td>
<td align="right">0.13</td>
</tr>
<tr class="odd">
<td>mechanic2</td>
<td align="right">-0.42</td>
<td align="right">-0.72</td>
<td align="right">-0.25</td>
<td align="right">-0.42</td>
<td align="right">-0.72</td>
<td align="right">-0.25</td>
</tr>
<tr class="even">
<td>construction_worker2</td>
<td align="right">-0.81</td>
<td align="right">0.04</td>
<td align="right">-0.22</td>
<td align="right">-0.81</td>
<td align="right">0.04</td>
<td align="right">-0.22</td>
</tr>
<tr class="odd">
<td>metalworker2</td>
<td align="right">-0.42</td>
<td align="right">-0.31</td>
<td align="right">0.69</td>
<td align="right">-0.42</td>
<td align="right">-0.31</td>
<td align="right">0.69</td>
</tr>
<tr class="even">
<td>cook_chef2</td>
<td align="right">0.72</td>
<td align="right">-0.08</td>
<td align="right">0.06</td>
<td align="right">0.72</td>
<td align="right">-0.08</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td>factory_manager2</td>
<td align="right">0.75</td>
<td align="right">0.17</td>
<td align="right">0.28</td>
<td align="right">0.75</td>
<td align="right">0.17</td>
<td align="right">0.28</td>
</tr>
<tr class="even">
<td>engineer2</td>
<td align="right">0.79</td>
<td align="right">0.05</td>
<td align="right">0.15</td>
<td align="right">0.79</td>
<td align="right">0.05</td>
<td align="right">0.15</td>
</tr>
<tr class="odd">
<td>bank_clerk2</td>
<td align="right">0.66</td>
<td align="right">0.33</td>
<td align="right">-0.11</td>
<td align="right">0.66</td>
<td align="right">0.33</td>
<td align="right">-0.11</td>
</tr>
<tr class="even">
<td>executive_secretary2</td>
<td align="right">0.77</td>
<td align="right">-0.07</td>
<td align="right">-0.14</td>
<td align="right">0.77</td>
<td align="right">-0.07</td>
<td align="right">-0.14</td>
</tr>
<tr class="odd">
<td>salesperson2</td>
<td align="right">0.19</td>
<td align="right">0.26</td>
<td align="right">-0.66</td>
<td align="right">0.19</td>
<td align="right">0.26</td>
<td align="right">-0.66</td>
</tr>
<tr class="even">
<td>textile_worker2</td>
<td align="right">-0.57</td>
<td align="right">0.43</td>
<td align="right">-0.19</td>
<td align="right">-0.57</td>
<td align="right">0.43</td>
<td align="right">-0.19</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>The first component shows the opposition of <code>executive_secretary</code>, <code>factory_manager</code>, <code>engineer</code>, <code>cook_chef</code>, and <code>bank_clerk</code> against the rest of the professions, and in particular with <code>construction_worker</code>.</p>
<p>The second axis is formed by the professions <code>mechanic</code>, and <code>metal_worker</code>, opposed to <code>teacher</code>, <code>bus_driver</code>, and <code>textile_worker</code>.</p>
<p>Having eliminated the size factor in this second analysis, we can say that the first factorial plane provides the structure of association among the professions with a constant global salary, with respect to all the cities (see figure <a href="mechanics.html#fig:fig-2-9">2.9</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-9"></span>
<img src="images/figure-2-9.png" alt="Circle of correlations on the first factorial plane of the second analysis" width="70%" />
<p class="caption">
Figure 2.9: Circle of correlations on the first factorial plane of the second analysis
</p>
</div>
<p>The results regarding the cities are shown in table <a href="mechanics.html#tab:table-2-9">2.9</a></p>
<table>
<caption><span id="tab:table-2-9">Table 2.9: </span>Results for the cities in the second analysis</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">city</th>
<th align="right">wgt</th>
<th align="right">disto</th>
<th align="right">coord1</th>
<th align="right">coord2</th>
<th align="right">contr1</th>
<th align="right">contr2</th>
<th align="right">cosqr1</th>
<th align="right">cosqr2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="left">AbuDhabi</td>
<td align="right">1.96</td>
<td align="right">55.78</td>
<td align="right">6.11</td>
<td align="right">2.41</td>
<td align="right">16.28</td>
<td align="right">6.65</td>
<td align="right">0.67</td>
<td align="right">0.10</td>
</tr>
<tr class="even">
<td>2</td>
<td align="left">Amsterdam</td>
<td align="right">1.96</td>
<td align="right">6.40</td>
<td align="right">-1.67</td>
<td align="right">1.30</td>
<td align="right">1.22</td>
<td align="right">1.93</td>
<td align="right">0.44</td>
<td align="right">0.26</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="left">Athens</td>
<td align="right">1.96</td>
<td align="right">6.94</td>
<td align="right">-1.62</td>
<td align="right">0.77</td>
<td align="right">1.15</td>
<td align="right">0.68</td>
<td align="right">0.38</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td>4</td>
<td align="left">Bangkok</td>
<td align="right">1.96</td>
<td align="right">36.42</td>
<td align="right">4.45</td>
<td align="right">-0.44</td>
<td align="right">8.65</td>
<td align="right">0.22</td>
<td align="right">0.54</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>5</td>
<td align="left">Bogota</td>
<td align="right">1.96</td>
<td align="right">19.81</td>
<td align="right">2.85</td>
<td align="right">-1.18</td>
<td align="right">3.56</td>
<td align="right">1.59</td>
<td align="right">0.41</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td>6</td>
<td align="left">Mumbai</td>
<td align="right">1.96</td>
<td align="right">6.23</td>
<td align="right">0.39</td>
<td align="right">0.27</td>
<td align="right">0.07</td>
<td align="right">0.09</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="left">Brussels</td>
<td align="right">1.96</td>
<td align="right">2.32</td>
<td align="right">-0.92</td>
<td align="right">0.25</td>
<td align="right">0.37</td>
<td align="right">0.07</td>
<td align="right">0.36</td>
<td align="right">0.03</td>
</tr>
<tr class="even">
<td>8</td>
<td align="left">Budapest</td>
<td align="right">1.96</td>
<td align="right">2.73</td>
<td align="right">-0.15</td>
<td align="right">0.17</td>
<td align="right">0.01</td>
<td align="right">0.03</td>
<td align="right">0.01</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="left">BuenosAires</td>
<td align="right">1.96</td>
<td align="right">38.32</td>
<td align="right">4.21</td>
<td align="right">-0.04</td>
<td align="right">7.76</td>
<td align="right">0.00</td>
<td align="right">0.46</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>11</td>
<td align="left">Caracas</td>
<td align="right">1.96</td>
<td align="right">37.27</td>
<td align="right">4.46</td>
<td align="right">-0.03</td>
<td align="right">8.68</td>
<td align="right">0.00</td>
<td align="right">0.53</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="left">Chicago</td>
<td align="right">1.96</td>
<td align="right">12.31</td>
<td align="right">-2.61</td>
<td align="right">-0.86</td>
<td align="right">2.98</td>
<td align="right">0.85</td>
<td align="right">0.55</td>
<td align="right">0.06</td>
</tr>
<tr class="even">
<td>13</td>
<td align="left">Copenhagen</td>
<td align="right">1.96</td>
<td align="right">5.26</td>
<td align="right">-1.53</td>
<td align="right">-0.85</td>
<td align="right">1.02</td>
<td align="right">0.83</td>
<td align="right">0.44</td>
<td align="right">0.14</td>
</tr>
<tr class="odd">
<td>14</td>
<td align="left">Dublin</td>
<td align="right">1.96</td>
<td align="right">3.58</td>
<td align="right">-0.85</td>
<td align="right">1.22</td>
<td align="right">0.31</td>
<td align="right">1.70</td>
<td align="right">0.20</td>
<td align="right">0.42</td>
</tr>
<tr class="even">
<td>15</td>
<td align="left">Dusseldorf</td>
<td align="right">1.96</td>
<td align="right">4.51</td>
<td align="right">-0.99</td>
<td align="right">1.60</td>
<td align="right">0.42</td>
<td align="right">2.93</td>
<td align="right">0.22</td>
<td align="right">0.57</td>
</tr>
<tr class="odd">
<td>16</td>
<td align="left">Frankfurt</td>
<td align="right">1.96</td>
<td align="right">3.19</td>
<td align="right">-0.51</td>
<td align="right">1.07</td>
<td align="right">0.11</td>
<td align="right">1.30</td>
<td align="right">0.08</td>
<td align="right">0.36</td>
</tr>
<tr class="even">
<td>17</td>
<td align="left">Geneva</td>
<td align="right">1.96</td>
<td align="right">4.86</td>
<td align="right">-1.51</td>
<td align="right">0.98</td>
<td align="right">0.99</td>
<td align="right">1.10</td>
<td align="right">0.47</td>
<td align="right">0.20</td>
</tr>
<tr class="odd">
<td>18</td>
<td align="left">Helsinki</td>
<td align="right">1.96</td>
<td align="right">3.53</td>
<td align="right">-1.55</td>
<td align="right">0.26</td>
<td align="right">1.05</td>
<td align="right">0.08</td>
<td align="right">0.68</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td>19</td>
<td align="left">Hongkong</td>
<td align="right">1.96</td>
<td align="right">28.00</td>
<td align="right">0.64</td>
<td align="right">3.40</td>
<td align="right">0.18</td>
<td align="right">13.18</td>
<td align="right">0.01</td>
<td align="right">0.41</td>
</tr>
<tr class="odd">
<td>20</td>
<td align="left">Houston</td>
<td align="right">1.96</td>
<td align="right">5.56</td>
<td align="right">-1.59</td>
<td align="right">-0.80</td>
<td align="right">1.11</td>
<td align="right">0.74</td>
<td align="right">0.46</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td>21</td>
<td align="left">Jakarta</td>
<td align="right">1.96</td>
<td align="right">23.97</td>
<td align="right">0.32</td>
<td align="right">-4.12</td>
<td align="right">0.05</td>
<td align="right">19.36</td>
<td align="right">0.00</td>
<td align="right">0.71</td>
</tr>
<tr class="odd">
<td>22</td>
<td align="left">Johannesburg</td>
<td align="right">1.96</td>
<td align="right">8.74</td>
<td align="right">0.07</td>
<td align="right">-1.51</td>
<td align="right">0.00</td>
<td align="right">2.61</td>
<td align="right">0.00</td>
<td align="right">0.26</td>
</tr>
<tr class="even">
<td>24</td>
<td align="left">Lagos</td>
<td align="right">1.96</td>
<td align="right">11.51</td>
<td align="right">-0.84</td>
<td align="right">-1.86</td>
<td align="right">0.31</td>
<td align="right">3.95</td>
<td align="right">0.06</td>
<td align="right">0.30</td>
</tr>
<tr class="odd">
<td>25</td>
<td align="left">Lisbon</td>
<td align="right">1.96</td>
<td align="right">3.02</td>
<td align="right">-0.65</td>
<td align="right">0.31</td>
<td align="right">0.19</td>
<td align="right">0.11</td>
<td align="right">0.14</td>
<td align="right">0.03</td>
</tr>
<tr class="even">
<td>26</td>
<td align="left">London</td>
<td align="right">1.96</td>
<td align="right">5.22</td>
<td align="right">-1.81</td>
<td align="right">-0.28</td>
<td align="right">1.44</td>
<td align="right">0.09</td>
<td align="right">0.63</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>27</td>
<td align="left">LosAngeles</td>
<td align="right">1.96</td>
<td align="right">14.72</td>
<td align="right">-3.01</td>
<td align="right">-0.24</td>
<td align="right">3.95</td>
<td align="right">0.07</td>
<td align="right">0.61</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>28</td>
<td align="left">Luxembourg</td>
<td align="right">1.96</td>
<td align="right">15.85</td>
<td align="right">-1.12</td>
<td align="right">2.89</td>
<td align="right">0.54</td>
<td align="right">9.56</td>
<td align="right">0.08</td>
<td align="right">0.53</td>
</tr>
<tr class="odd">
<td>29</td>
<td align="left">Madrid</td>
<td align="right">1.96</td>
<td align="right">1.99</td>
<td align="right">-0.07</td>
<td align="right">0.05</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>30</td>
<td align="left">Manama</td>
<td align="right">1.96</td>
<td align="right">30.51</td>
<td align="right">4.09</td>
<td align="right">0.75</td>
<td align="right">7.32</td>
<td align="right">0.64</td>
<td align="right">0.55</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td>31</td>
<td align="left">Manila</td>
<td align="right">1.96</td>
<td align="right">7.96</td>
<td align="right">1.95</td>
<td align="right">0.35</td>
<td align="right">1.65</td>
<td align="right">0.14</td>
<td align="right">0.48</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td>32</td>
<td align="left">Mexico</td>
<td align="right">1.96</td>
<td align="right">17.53</td>
<td align="right">0.42</td>
<td align="right">-1.71</td>
<td align="right">0.08</td>
<td align="right">3.35</td>
<td align="right">0.01</td>
<td align="right">0.17</td>
</tr>
<tr class="odd">
<td>33</td>
<td align="left">Milan</td>
<td align="right">1.96</td>
<td align="right">4.62</td>
<td align="right">-1.20</td>
<td align="right">0.44</td>
<td align="right">0.63</td>
<td align="right">0.23</td>
<td align="right">0.31</td>
<td align="right">0.04</td>
</tr>
<tr class="even">
<td>34</td>
<td align="left">Montreal</td>
<td align="right">1.96</td>
<td align="right">4.21</td>
<td align="right">-1.75</td>
<td align="right">-0.39</td>
<td align="right">1.34</td>
<td align="right">0.17</td>
<td align="right">0.73</td>
<td align="right">0.04</td>
</tr>
<tr class="odd">
<td>35</td>
<td align="left">Nairobi</td>
<td align="right">1.96</td>
<td align="right">39.30</td>
<td align="right">4.67</td>
<td align="right">-2.27</td>
<td align="right">9.50</td>
<td align="right">5.89</td>
<td align="right">0.55</td>
<td align="right">0.13</td>
</tr>
<tr class="even">
<td>36</td>
<td align="left">NewYork</td>
<td align="right">1.96</td>
<td align="right">3.79</td>
<td align="right">-1.51</td>
<td align="right">-0.17</td>
<td align="right">0.99</td>
<td align="right">0.03</td>
<td align="right">0.60</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>37</td>
<td align="left">Nicosia</td>
<td align="right">1.96</td>
<td align="right">5.49</td>
<td align="right">-1.20</td>
<td align="right">0.80</td>
<td align="right">0.63</td>
<td align="right">0.73</td>
<td align="right">0.26</td>
<td align="right">0.12</td>
</tr>
<tr class="even">
<td>38</td>
<td align="left">Oslo</td>
<td align="right">1.96</td>
<td align="right">4.79</td>
<td align="right">-1.54</td>
<td align="right">-0.14</td>
<td align="right">1.04</td>
<td align="right">0.02</td>
<td align="right">0.50</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>39</td>
<td align="left">Panama</td>
<td align="right">1.96</td>
<td align="right">17.66</td>
<td align="right">2.32</td>
<td align="right">0.90</td>
<td align="right">2.36</td>
<td align="right">0.93</td>
<td align="right">0.31</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td>40</td>
<td align="left">Paris</td>
<td align="right">1.96</td>
<td align="right">5.14</td>
<td align="right">0.81</td>
<td align="right">1.28</td>
<td align="right">0.29</td>
<td align="right">1.86</td>
<td align="right">0.13</td>
<td align="right">0.32</td>
</tr>
<tr class="odd">
<td>41</td>
<td align="left">Prague</td>
<td align="right">1.96</td>
<td align="right">7.22</td>
<td align="right">-0.60</td>
<td align="right">-1.40</td>
<td align="right">0.16</td>
<td align="right">2.23</td>
<td align="right">0.05</td>
<td align="right">0.27</td>
</tr>
<tr class="even">
<td>42</td>
<td align="left">RiodeJaneiro</td>
<td align="right">1.96</td>
<td align="right">25.04</td>
<td align="right">3.07</td>
<td align="right">0.28</td>
<td align="right">4.11</td>
<td align="right">0.09</td>
<td align="right">0.38</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>43</td>
<td align="left">SaoPaulo</td>
<td align="right">1.96</td>
<td align="right">9.06</td>
<td align="right">0.95</td>
<td align="right">-2.00</td>
<td align="right">0.40</td>
<td align="right">4.58</td>
<td align="right">0.10</td>
<td align="right">0.44</td>
</tr>
<tr class="even">
<td>44</td>
<td align="left">Seoul</td>
<td align="right">1.96</td>
<td align="right">2.24</td>
<td align="right">-0.79</td>
<td align="right">0.02</td>
<td align="right">0.28</td>
<td align="right">0.00</td>
<td align="right">0.28</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>45</td>
<td align="left">Singapore</td>
<td align="right">1.96</td>
<td align="right">14.77</td>
<td align="right">-0.28</td>
<td align="right">-1.14</td>
<td align="right">0.03</td>
<td align="right">1.48</td>
<td align="right">0.01</td>
<td align="right">0.09</td>
</tr>
<tr class="even">
<td>46</td>
<td align="left">Stockholm</td>
<td align="right">1.96</td>
<td align="right">8.11</td>
<td align="right">-1.90</td>
<td align="right">0.29</td>
<td align="right">1.57</td>
<td align="right">0.10</td>
<td align="right">0.44</td>
<td align="right">0.01</td>
</tr>
<tr class="odd">
<td>47</td>
<td align="left">Sidney</td>
<td align="right">1.96</td>
<td align="right">3.59</td>
<td align="right">-0.66</td>
<td align="right">0.40</td>
<td align="right">0.19</td>
<td align="right">0.19</td>
<td align="right">0.12</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td>48</td>
<td align="left">Taipei</td>
<td align="right">1.96</td>
<td align="right">7.90</td>
<td align="right">-1.40</td>
<td align="right">-1.13</td>
<td align="right">0.86</td>
<td align="right">1.46</td>
<td align="right">0.25</td>
<td align="right">0.16</td>
</tr>
<tr class="odd">
<td>49</td>
<td align="left">Tel-Aviv</td>
<td align="right">1.96</td>
<td align="right">6.51</td>
<td align="right">-0.28</td>
<td align="right">-1.53</td>
<td align="right">0.03</td>
<td align="right">2.68</td>
<td align="right">0.01</td>
<td align="right">0.36</td>
</tr>
<tr class="even">
<td>50</td>
<td align="left">Tokyo</td>
<td align="right">1.96</td>
<td align="right">2.50</td>
<td align="right">-0.84</td>
<td align="right">0.38</td>
<td align="right">0.31</td>
<td align="right">0.17</td>
<td align="right">0.28</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td>51</td>
<td align="left">Toronto</td>
<td align="right">1.96</td>
<td align="right">7.00</td>
<td align="right">-2.38</td>
<td align="right">-0.24</td>
<td align="right">2.47</td>
<td align="right">0.06</td>
<td align="right">0.81</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td>52</td>
<td align="left">Vienna</td>
<td align="right">1.96</td>
<td align="right">1.93</td>
<td align="right">-1.02</td>
<td align="right">-0.21</td>
<td align="right">0.45</td>
<td align="right">0.05</td>
<td align="right">0.54</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td>53</td>
<td align="left">Zurich</td>
<td align="right">1.96</td>
<td align="right">7.08</td>
<td align="right">-1.46</td>
<td align="right">1.68</td>
<td align="right">0.92</td>
<td align="right">3.21</td>
<td align="right">0.30</td>
<td align="right">0.40</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>There are few cities farther apart from the center of gravity: Abu Dhabi, Nairobi, and Buenos Aires. Figure <a href="mechanics.html#fig:fig-2-10">2.10</a> shows the factorial plane. On the left side we find the cities with salaries of “managerial” professions <em>relatively</em> higher. To the right of the graph we find cities that could be labeled as more “egalitarian” (in terms of their salaries).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-10"></span>
<img src="images/figure-2-10.png" alt="Projection of the individuals in the first factorial plane" width="80%" />
<p class="caption">
Figure 2.10: Projection of the individuals in the first factorial plane
</p>
</div>
<p>In the lower half of the graph we find cities that provide more value to the qualified manual jobs, whereas the upper half of the graph contains cities that tend to provide more value to the managerial and services types of jobs.</p>
<p>All these results suggest that the salaries can be explained from the level of salaries of each city (first factor from first analysis), the degree of “egalitarianism” between professions and the orientation of the types of jobs (manual jobs versus service jobs).</p>
</div>
<div id="using-supplementary-elements" class="section level2">
<h2><span class="header-section-number">2.4</span> Using Supplementary Elements</h2>
<p>In section 1.1 we described the data set containing 51 cities on which 40 economic variables have been measured. Until now we have performed a couple of Principal Component Analysis using only the so-called active variables (i.e. the variables about the salaries of 12 professions). However, the data table contains additional variables that can be taken into account in order to enrich our analysis.</p>
<div id="continuous-supplementary-variables" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Continuous Supplementary Variables</h3>
<p>The continuous supplementary variables can be positioned in the factorial spcaes using the same formulas applied to the active variables.</p>
<p>Within a normalized PCA, we use the correlation of a supplementary variable <span class="math inline">\(\mathbf{x^{+}_{j}}\)</span> with the principal components <span class="math inline">\(\boldsymbol{\psi_{\alpha}}\)</span></p>
<p><span class="math display" id="eq:2-16">\[
\phi^{+}_{j \alpha} = cor(\mathbf{x^{+}_{j}}, \boldsymbol{\psi_{\alpha}})
\tag{2.16}
\]</span></p>
<p>(the superindex + indicates that this is a supplementary variable)</p>
<p>With a non-normalized PCA, we just need to multiply the correlation by the standard deviation of the supplementary variable:</p>
<p><span class="math display" id="eq:2-17">\[
\phi^{+}_{j \alpha} = s_j \hspace{1mm} cor(\mathbf{x^{+}_{j}}, \boldsymbol{\psi_{\alpha}})
\tag{2.17}
\]</span></p>
<p>The position of the supplementary variables with respect to the factorial axes is interpreted in the same way as with the active variables.</p>
<p><em>The position of a supplementary variable in a factorial plane allows us to visualize the relationship of the variable with the set of active variables via the factorial axes.</em></p>
<p>Notice that we have not defined a distance between two supplementary variables. The relative positions between two supplementary variables does not imply any correlation between them. However, as long as the supplementary variables are well represented on the first factorial plane, and close to each other, we can expect that the similarity of their correlations with the axes (similarity of their coordinates) is a consequence of a strong correlation between them.</p>
<div id="visualized-regression" class="section level4 unnumbered">
<h4>Visualized Regression</h4>
<p>The position of a continuous supplementary variable in a factorial plane resembles that of a “visual regression”. From this point of view, the supplementary variable plays the role of response variable. In turn, the projection subspace (first factorial planes) play the role of explanatory variables. This analogy is depicted in figure <a href="mechanics.html#fig:fig-2-11">2.11</a></p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-11"></span>
<img src="images/figure-2-11.png" alt="Equivalence between a regression and the projection of supplementary" width="80%" />
<p class="caption">
Figure 2.11: Equivalence between a regression and the projection of supplementary
</p>
</div>
<p>In a regression, we are mostly interested in the value of the coefficients, and we care about whether the explanatory variables allows us to predict the response variable <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>In a PCA, there is usually a considerable number of variables of type <span class="math inline">\(\mathbf{y}\)</span>. Their projections onto the first factorial plane indicate, in a quick way, which are well (or not) related with the set of active variables. On the other hand, their positions with respect the axes provide what we call interpretation elements of the axes.</p>
</div>
<div id="quality-of-representation-for-supplementary-variables" class="section level4 unnumbered">
<h4>Quality of Representation for Supplementary Variables</h4>
<p>To compute the quality of representation for the supplementary variables we calculate the squared cosines of each supplementary variable with the different factorial axes. Keep in mind that the overall sum of the squared cosines on the <span class="math inline">\(p\)</span> axes will (in general) be less than one.</p>
<p><span class="math display">\[
COS^2 (j^{+}, \alpha) = cor^2 (\text{variable}^{+}, \text{factor})
\]</span></p>
<p>To get the location of a supplementary variable in the original space, we need to know its <span class="math inline">\(n\)</span> elements (its values for the <span class="math inline">\(n\)</span> individuals). This is analogous to an active variable, except that the set of active variables is found in a subset of dimension <span class="math inline">\(p\)</span> (the rank of <span class="math inline">\(\mathbf{X}\)</span>, or the rank of <span class="math inline">\(\mathbf{X^\mathsf{T} X}\)</span>). The coordinates on the <span class="math inline">\(p\)</span> factorial axes allow to locate any active variable. This property is not present for supplementary variables.</p>
<p>It doesn’t make sense to calculate the contributions of the supplementary variables to the inertia of the axes, because these variables have not intervened in its construction.</p>
<p>In the second analysis of the cities, we have decided to treat the following variables as supplementary variables: the 12 active variables used in the first PCA, the rest of the 16 continuous variables, as well as the variables derived in the 2nd analysis, namely, <code>salary_inequality</code> and <code>manual_qualified</code>. In addition, we have also decided to consider the five axes obtained in the first analysis as supplementary variables; we do this to study the relationship of both PCA analyses.</p>
<table>
<caption><span id="tab:table-2-10">Table 2.10: </span>Results of the continuous supplementary variables</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Dim.1</th>
<th align="right">Dim.2</th>
<th align="right">Dim.3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>price_index_no_rent</td>
<td align="right">-0.35</td>
<td align="right">0.22</td>
<td align="right">-0.09</td>
</tr>
<tr class="even">
<td>price_index_with_rent</td>
<td align="right">-0.31</td>
<td align="right">0.26</td>
<td align="right">0.05</td>
</tr>
<tr class="odd">
<td>gross_salaries</td>
<td align="right">-0.61</td>
<td align="right">0.37</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td>net_salaries</td>
<td align="right">-0.58</td>
<td align="right">0.39</td>
<td align="right">0.05</td>
</tr>
<tr class="odd">
<td>work_hours_year</td>
<td align="right">0.46</td>
<td align="right">-0.09</td>
<td align="right">0.18</td>
</tr>
<tr class="even">
<td>paid_vacations_year</td>
<td align="right">0.10</td>
<td align="right">0.34</td>
<td align="right">-0.11</td>
</tr>
<tr class="odd">
<td>gross_buying_power</td>
<td align="right">-0.67</td>
<td align="right">0.37</td>
<td align="right">0.03</td>
</tr>
<tr class="even">
<td>net_buying_power</td>
<td align="right">-0.62</td>
<td align="right">0.39</td>
<td align="right">0.07</td>
</tr>
<tr class="odd">
<td>bread_kg_work_time</td>
<td align="right">0.42</td>
<td align="right">-0.28</td>
<td align="right">-0.15</td>
</tr>
<tr class="even">
<td>burger_work_time</td>
<td align="right">0.22</td>
<td align="right">-0.33</td>
<td align="right">-0.26</td>
</tr>
<tr class="odd">
<td>food_expenses</td>
<td align="right">-0.29</td>
<td align="right">0.15</td>
<td align="right">-0.10</td>
</tr>
<tr class="even">
<td>shopping_basket</td>
<td align="right">-0.35</td>
<td align="right">0.21</td>
<td align="right">-0.09</td>
</tr>
<tr class="odd">
<td>women_apparel</td>
<td align="right">-0.13</td>
<td align="right">0.14</td>
<td align="right">-0.05</td>
</tr>
<tr class="even">
<td>men_apparel</td>
<td align="right">-0.11</td>
<td align="right">0.21</td>
<td align="right">-0.16</td>
</tr>
<tr class="odd">
<td>bed4_apt_furnished</td>
<td align="right">0.08</td>
<td align="right">0.21</td>
<td align="right">0.37</td>
</tr>
<tr class="even">
<td>bed3_apt_unfurnished</td>
<td align="right">0.06</td>
<td align="right">0.08</td>
<td align="right">0.45</td>
</tr>
<tr class="odd">
<td>rent_cost</td>
<td align="right">-0.28</td>
<td align="right">0.33</td>
<td align="right">0.30</td>
</tr>
<tr class="even">
<td>home_appliances</td>
<td align="right">0.12</td>
<td align="right">-0.15</td>
<td align="right">-0.16</td>
</tr>
<tr class="odd">
<td>public_transportation</td>
<td align="right">-0.58</td>
<td align="right">0.31</td>
<td align="right">-0.12</td>
</tr>
<tr class="even">
<td>taxi</td>
<td align="right">-0.49</td>
<td align="right">0.26</td>
<td align="right">-0.12</td>
</tr>
<tr class="odd">
<td>car</td>
<td align="right">-0.10</td>
<td align="right">-0.13</td>
<td align="right">0.38</td>
</tr>
<tr class="even">
<td>restaurant</td>
<td align="right">-0.22</td>
<td align="right">0.12</td>
<td align="right">0.28</td>
</tr>
<tr class="odd">
<td>hotel_night</td>
<td align="right">-0.18</td>
<td align="right">0.22</td>
<td align="right">-0.03</td>
</tr>
<tr class="even">
<td>various_services</td>
<td align="right">-0.37</td>
<td align="right">0.27</td>
<td align="right">-0.04</td>
</tr>
<tr class="odd">
<td>tax_pct_gross_salary</td>
<td align="right">-0.68</td>
<td align="right">0.17</td>
<td align="right">-0.19</td>
</tr>
<tr class="even">
<td>net_hourly_salary</td>
<td align="right">-0.58</td>
<td align="right">0.38</td>
<td align="right">0.05</td>
</tr>
<tr class="odd">
<td>teacher</td>
<td align="right">-0.51</td>
<td align="right">0.50</td>
<td align="right">0.18</td>
</tr>
<tr class="even">
<td>bus_driver</td>
<td align="right">-0.56</td>
<td align="right">0.43</td>
<td align="right">0.14</td>
</tr>
<tr class="odd">
<td>mechanic</td>
<td align="right">-0.62</td>
<td align="right">0.13</td>
<td align="right">-0.01</td>
</tr>
<tr class="even">
<td>construction_worker</td>
<td align="right">-0.69</td>
<td align="right">0.21</td>
<td align="right">-0.01</td>
</tr>
<tr class="odd">
<td>metalworker</td>
<td align="right">-0.63</td>
<td align="right">0.28</td>
<td align="right">0.21</td>
</tr>
<tr class="even">
<td>cook_chef</td>
<td align="right">-0.25</td>
<td align="right">0.37</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td>factory_manager</td>
<td align="right">-0.04</td>
<td align="right">0.52</td>
<td align="right">0.16</td>
</tr>
<tr class="even">
<td>engineer</td>
<td align="right">-0.25</td>
<td align="right">0.51</td>
<td align="right">0.11</td>
</tr>
<tr class="odd">
<td>bank_clerk</td>
<td align="right">-0.14</td>
<td align="right">0.54</td>
<td align="right">-0.02</td>
</tr>
<tr class="even">
<td>executive_secretary</td>
<td align="right">-0.43</td>
<td align="right">0.45</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td>salesperson</td>
<td align="right">-0.46</td>
<td align="right">0.42</td>
<td align="right">-0.10</td>
</tr>
<tr class="even">
<td>textile_worker</td>
<td align="right">-0.63</td>
<td align="right">0.40</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td>Axis1</td>
<td align="right">-0.48</td>
<td align="right">0.43</td>
<td align="right">0.07</td>
</tr>
<tr class="even">
<td>Axis2</td>
<td align="right">0.72</td>
<td align="right">0.39</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td>Axis3</td>
<td align="right">0.01</td>
<td align="right">-0.37</td>
<td align="right">-0.23</td>
</tr>
<tr class="even">
<td>Axis4</td>
<td align="right">0.01</td>
<td align="right">-0.08</td>
<td align="right">0.03</td>
</tr>
<tr class="odd">
<td>Axis5</td>
<td align="right">-0.05</td>
<td align="right">0.01</td>
<td align="right">0.71</td>
</tr>
<tr class="even">
<td>salary_inequality</td>
<td align="right">0.87</td>
<td align="right">0.07</td>
<td align="right">0.23</td>
</tr>
<tr class="odd">
<td>manual_qualified</td>
<td align="right">-0.55</td>
<td align="right">-0.68</td>
<td align="right">0.27</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>From the above table, we see that the salaries of the 12 professions, as well as most of the expenses, are negatively correlated with the first dimension. This indicates that the cities with higher salaries tend to remunerate (relatively) less the managerial professions.</p>
<p>Also, the correlations with the variables <code>price_index_no_rent</code> and <code>price_index_with_rent</code> are a bit smaller than the correlations with the variables <code>gross_salaries</code> and <code>net_salaries</code>. This has to do with the most expensive cities which have a higher buying capacity, and elevated taxes and social services.</p>
<p>The first axis opposes cities with low salaries that pay relatively well to <code>factory_manager</code>, <code>engineer</code> and <code>executive_secretary</code>, to the cities with higher salaries that pay relatively better those professions that are less socially well considered. This axis can thus be labeled as a <em>salary inequality</em>. In fact, the derived variable <code>salary_inequality</code> is the most correlated to this axis.</p>
<p>This first axis is correlated to the first axis of the first PCA analysis (i.e. the so-called <em>size effect</em>). In other words, the first axis of salary inequality is correlated to the salary level: the higher the level of salary, the less the salary inequality. However, notice that the largest correlation occurs with the second axis from the first analysis. This indicates a rotation: the first axis from the analysis on the ratios corresponds to the second axis from the analysis on the raw data. This is a common phenomenon that occurs in an analysis in which we eliminate the size effect.</p>
</div>
</div>
<div id="nominal-supplementary-variables" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Nominal Supplementary Variables</h3>
<p>A categorical variable observed on a set of individuals defines a partition of such individuals into groups; there are as many groups as categories in the variable.</p>
<p>When considering the cloud of row-points, we can distinguish the various groups of individuals for each category. For each group of points we can calculate the <em>average point</em> or center of gravity (see figure <a href="mechanics.html#fig:fig-2-12">2.12</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-12"></span>
<img src="images/figure-2-12.png" alt="Partition of individuals based on a nominal variable" width="80%" />
<p class="caption">
Figure 2.12: Partition of individuals based on a nominal variable
</p>
</div>
<p>The projection of a supplementary categorical variable is the projection of the centroids onto the space of row-points. We obtain as many projected points as categories of the nominal variable.</p>
<p>In our working example, we use the variable <code>region</code> as the supplementary categorical variable. In this case we obtain the following representation in the first factorial plane (see figure <a href="mechanics.html#fig:fig-2-13">2.13</a>). Each category groups the cities of a given <code>region</code> of the world.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-13"></span>
<img src="images/figure-2-13.png" alt="Regions of the world as supplementary categories (second PCA analysis)" width="80%" />
<p class="caption">
Figure 2.13: Regions of the world as supplementary categories (second PCA analysis)
</p>
</div>
<p>This plot provides a simplified visualization of the cloud of row-points according to the chosen supplementary categorical variable—in this case <code>region</code>. The configuration of the category-points allows us to assess certain areas of the graph. This could suggest some elements useful in the interpretation of the factorial directions. For example, the opposition of Europe and North America against the rest of the world regions.</p>
<div id="supplementary-category-and-supplementary-individual" class="section level4 unnumbered">
<h4>Supplementary Category and Supplementary Individual</h4>
<p>In summary, a supplementary category is positioned as the average point (i.e. centroid) of the individuals that form such category. Consequently, the definition of a nominal variable with three categories is equivalent to defining three supplementary individuals equal to the center of gravity of the active variables for each category. The supplementary individuals are located in the same factorial plane as the active individuals, with the same rules of interpretation.</p>
</div>
</div>
<div id="profiling-with-v-test" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Profiling with V-test</h3>
<p>The projection of a category is interpreted as the position of the average individual of the group defined by such category—the centroid. This position can be close to the center of gravity of all the individuals (i.e. the origin of the factorial coordinates).</p>
<p>The proximity to the overall center of gravity suggests that there is little difference between the individuals that have such category and the set of all the individuals.</p>
<p>In contrast, when the projected category is clearly separated from the overall centroid, this indicates that there is a relationship between the active variables and the given category.</p>
<p>It would be interesting to assess what category (i.e group of individuals) seems to indicate an relevant area in the factorial plane.</p>
<p>We can regard the overall center of gravity to be the <em>center of atraction</em> of al the average points of all groups randomly selected. By doing this, we can highlight those centroids that differ “significantly” from the overall centroid. The individuals that form such group will have a high degree of resemblance among them, and therefore will be sufficiently unique to differentiate themselves from the center of gravity.</p>
<p>Suppose that we randomly select a group of <span class="math inline">\(n_j\)</span> individuals from the total of <span class="math inline">\(n\)</span> individuals. The graph of these individuals over the first factorial plane will be a a random scatter plot over this plane.</p>
<p>The average point of these <span class="math inline">\(n_j\)</span> individuals will differ only by the random fluctuations from the overall average represented by the origin of the coordinates (see figure <a href="mechanics.html#fig:fig-2-14">2.14</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-14"></span>
<img src="images/figure-2-14.png" alt="Random selection of a group of individuals" width="75%" />
<p class="caption">
Figure 2.14: Random selection of a group of individuals
</p>
</div>
<p>Suppose that we repeat the random selection of <span class="math inline">\(n_j\)</span> individuals a large number of times. For each repetition we calculate the average point of the selected individuals. We should expect the center of all these groups to coincide with the overall center of gravity.</p>
<p>Now, suppose that a set of <span class="math inline">\(n_k\)</span> individuals having the same category, non-randomly selected, are located in a certain region of the factorial plane (see figure <a href="mechanics.html#fig:fig-2-15">2.15</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-15"></span>
<img src="images/figure-2-15.png" alt="Group of individuals defined by a certain category" width="75%" />
<p class="caption">
Figure 2.15: Group of individuals defined by a certain category
</p>
</div>
<p>We can calculate the average point of these individuals. Furthermore, we can compute the distance between this average point and the overall centroid. Is the position of this average point compatible with the hypothesis that the individuals have been randomly selected? The more the evidence againts this hypothesis, the more interesting this category will be to profile the region of the factorial plane that it occupies.</p>
<div id="interpreting-results-with-the-v-test" class="section level4 unnumbered">
<h4>Interpreting results with the V-test</h4>
<p>The idea behind the so-called V-test involves performing a hypothesis test. The null hypothesis <span class="math inline">\(H_0\)</span> consists in the assumption that a set of <span class="math inline">\(k\)</span> individuals are randomly selected, without replacement, from the total of <span class="math inline">\(n\)</span> individuals.</p>
<p>Under the null hypothesis, we calculate the probability of observing a configuration as the one obtained, or more extreme. This is the critical probability associated to <span class="math inline">\(H_0\)</span>. The smaller this probability, the less likely is the hypothesis of individuals being randomly selected.</p>
<p>In order to classify the elements in terms of importance, we rank them based on their critical probability. The elements that are most characteristic are those with a smaller critical probability.</p>
<p>The more significant is the difference between the average of the coordinates in group <span class="math inline">\(k\)</span> and the overall centroid, the more interesting the position will be of this group in the factorial plane.</p>
<p>Let <span class="math inline">\(m\)</span> be the average of the coordinates and <span class="math inline">\(s^2\)</span> the empirical variance calculated from the <span class="math inline">\(n\)</span> observations, which will be equal to the eigenvalue of the corresponding axis. Let <span class="math inline">\(m_k\)</span> be the average of the <span class="math inline">\(n_k\)</span> observations in group <span class="math inline">\(k\)</span>. We call <span class="math inline">\(M_k\)</span> to the random variable “average of the <span class="math inline">\(k\)</span> extractions.” Under the null hypothesis of random selection without replacement from a <em>finite populatoin</em>, we have that:</p>
<p><span class="math display">\[\begin{align*}
E_{H_0} [M_k] &amp;= 0 \\
Var_{H_0} [M_k] &amp;= \frac{n - n_k}{n - 1} \times \frac{\lambda_{\alpha}}{n_k} = s^{2}_{k}
\end{align*}\]</span></p>
<p>The average <span class="math inline">\(M_k\)</span> coincides with the average of the coordinates (<span class="math inline">\(\sum_i \psi_{i\alpha} = 0\)</span>) and its variance is equal to the variance of the coordinates of the axis <span class="math inline">\(\alpha\)</span> (<span class="math inline">\(\lambda_{\alpha}\)</span>) divided by the number of observations from group <span class="math inline">\(k\)</span> and scaled by the factor <span class="math inline">\((n - n_k) / (n-1)\)</span>.</p>
<p>If <span class="math inline">\(n\)</span> and <span class="math inline">\(n_k\)</span> are not very small, the central limit theorem is applicable (even though the extractions are not independent) and in this case the variable:</p>
<p><span class="math display">\[
U = \frac{M_k - m}{s_k}
\]</span></p>
<p>approximately follows a standard normal distribution.</p>
<p>The critical probability associated to this variable is the probability of a normal distribution of observing a value greater than <span class="math inline">\(u\)</span> calculated on the <span class="math inline">\(n_k\)</span> individuals for the random variable <span class="math inline">\(U\)</span>.</p>
<p>We obtain the most characterizing probabilities of an axis, selecting the categories with the smaller critical probabilities. This is equivalent to selecting the categories that have the larger values:</p>
<p><span class="math display" id="eq:2-18">\[
u = \frac{m_k - m}{s_k}
\tag{2.18}
\]</span></p>
<p>The statistic <span class="math inline">\(u\)</span> is what we call the <strong>v-test</strong>. This value expresses, in number of standard deviations, the difference between the average <span class="math inline">\(m_k\)</span> of group <span class="math inline">\(k\)</span>, and the overall average <span class="math inline">\(m\)</span>.</p>
<p>We interpret this value as follows: the probability of having a difference between both averages is the probability of exceeding this number of standard deviations in a normal distribution.</p>
<p>What we are doing is evaluating some sort of distance between the overall average and the average of a group, measured in terms of standard deviations from a normal distribution. By standardizing these values, we have a common unit that allows us to compare different categories, and rank them according to their importance. In this way, we assess the likelihood of the null hypothesis: that individuals from category <span class="math inline">\(k\)</span> have been randomly selected.</p>
<p>The larger this p-value (in absolute value), the more this indicates that the group of individuals occupies a significant position, and characterizes the region of the factorial plane where they are.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-16"></span>
<img src="images/figure-2-16.png" alt="V-test associated to a critical probability" width="55%" />
<p class="caption">
Figure 2.16: V-test associated to a critical probability
</p>
</div>
<p>In practice, we often use the threshold of 2 standard deviations in order to determine if the variable is significant.</p>
<p>Values larger than 2 indicate less likely value under the null hypothesis of random selection. We can think that these individuals have some kind of relationship with the set of active variables, which makes them have an excentric position in the cloud of individuals.</p>
<p>However, we should take into account the total number of individuals. One could double the data table indefinitly to make the v-test as large as desired.</p>
<p>We must say that the v-test is used as a tool to arrange the categories according to their association with the factorial axes. We don’t really use the v-test to formally test a null hypothesis.</p>
<p>In our working examples of the cities, we have a nominal categorical variable: the region of the world in which a city is located. This variable allows us to obtain a simplified representation of the cloud of cities. The results obtained with the first three axes are displayed in <a href="mechanics.html#tab:table-2-11">2.11</a>.</p>
<table>
<caption><span id="tab:table-2-11">Table 2.11: </span>V-test of the variable <code>world region</code>, used in the second PCA.</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">EFF</th>
<th align="right">PABS</th>
<th align="right">vtest1</th>
<th align="right">vtest2</th>
<th align="right">vtest3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Northern Europe</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">-1.9</td>
<td align="right">-0.2</td>
<td align="right">1.3</td>
</tr>
<tr class="even">
<td>Central Europe</td>
<td align="right">9</td>
<td align="right">9</td>
<td align="right">-1.4</td>
<td align="right">-3.0</td>
<td align="right">-0.9</td>
</tr>
<tr class="odd">
<td>Southern Europe</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">-1.0</td>
<td align="right">-0.8</td>
<td align="right">0.7</td>
</tr>
<tr class="even">
<td>Africa</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">1.1</td>
<td align="right">2.5</td>
<td align="right">0.7</td>
</tr>
<tr class="odd">
<td>East Asia</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">-0.6</td>
<td align="right">-0.5</td>
<td align="right">-1.4</td>
</tr>
<tr class="even">
<td>South Asia and Australia</td>
<td align="right">5</td>
<td align="right">5</td>
<td align="right">1.4</td>
<td align="right">1.3</td>
<td align="right">-1.7</td>
</tr>
<tr class="odd">
<td>North America</td>
<td align="right">7</td>
<td align="right">7</td>
<td align="right">-2.4</td>
<td align="right">1.4</td>
<td align="right">-0.2</td>
</tr>
<tr class="even">
<td>South America</td>
<td align="right">6</td>
<td align="right">6</td>
<td align="right">3.6</td>
<td align="right">0.7</td>
<td align="right">1.9</td>
</tr>
<tr class="odd">
<td>Middle East</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">2.8</td>
<td align="right">-0.7</td>
<td align="right">-0.5</td>
</tr>
<tr class="even">
<td>Eastern Europe</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">-0.3</td>
<td align="right">0.7</td>
<td align="right">0.5</td>
</tr>
</tbody>
</table>
<p>The first column, named <code>EFF</code>, provides the effective of each category (total number of cities of each category). The second column, named <code>PABS</code> provides the weight (sum of the weights of all the cities in a given category). When we have uniform weights, the weight and the effective are the same. The first category is formed by six cities of Northern Europe.</p>
<p>The v-test controlled, for each axis, the hypothesis of random distribution for these 6 cities among the 51 cities. In the first axis, for example, we see a significant opposition of North America with respect to South America and Middle East.</p>
<p>The second axis separates with significant v-tests the cities of Central Europe with the cities in Africa.</p>
</div>
</div>
<div id="axes-characterization-using-continuous-variables" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Axes Characterization using Continuous Variables</h3>
<p>We’ve seen that on each axis we have the projection of the active continuous variables, of the supplementary continuous variables, of the individuals, as well as the categories of supplementary qualitative variables.</p>
<p>In order to interpret the axes we should pay attention to the projected elements in their extremes. A first quick approximation to characterize the axes involves listing the projected elements on their more extreme positions (with coordinates further from the origin). To sort the categories we can use the larger v-tests on each axis.</p>
<p>With our working example about the international cities, the continuous variables—both active and supplementary—are arranged based on their correlation displayed in table <a href="mechanics.html#tab:table-2-12">2.12</a>.</p>
<table>
<caption><span id="tab:table-2-12">Table 2.12: </span>Characterization of the first axis from second PCA.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">scale</th>
<th align="left">type</th>
<th align="right">coord</th>
<th align="right">weight</th>
<th align="right">mean</th>
<th align="right">stdev</th>
<th align="right">number</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>construction_worker2</td>
<td align="left">continuous</td>
<td align="left">active</td>
<td align="right">-0.81</td>
<td align="right">51</td>
<td align="right">0.72</td>
<td align="right">0.27</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>engineer2</td>
<td align="left">continuous</td>
<td align="left">active</td>
<td align="right">0.79</td>
<td align="right">51</td>
<td align="right">2.12</td>
<td align="right">0.75</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td>construction_worker</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.69</td>
<td align="right">51</td>
<td align="right">10343.14</td>
<td align="right">8239.82</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>tax_pct_gross_salary</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.68</td>
<td align="right">51</td>
<td align="right">20.04</td>
<td align="right">9.54</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td>gross_buying_power</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.67</td>
<td align="right">51</td>
<td align="right">56.53</td>
<td align="right">31.89</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td>textile_worker</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.63</td>
<td align="right">51</td>
<td align="right">9247.06</td>
<td align="right">6429.78</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td>work_hours_year</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.46</td>
<td align="right">51</td>
<td align="right">1920.25</td>
<td align="right">158.69</td>
<td align="right">43</td>
</tr>
<tr class="even">
<td>Axis1</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.48</td>
<td align="right">51</td>
<td align="right">0.00</td>
<td align="right">3.18</td>
<td align="right">44</td>
</tr>
<tr class="odd">
<td>Axis2</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.72</td>
<td align="right">51</td>
<td align="right">0.00</td>
<td align="right">0.93</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td>salary_inequality</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.88</td>
<td align="right">51</td>
<td align="right">2.23</td>
<td align="right">1.42</td>
<td align="right">56</td>
</tr>
</tbody>
</table>
<p>We can easily identify the variables that are more correlated with the first axis. The second axis opposes the <code>mechanic</code> with the rest of the professions, especially <code>teacher</code> (see table <a href="mechanics.html#tab:table-2-13">2.13</a>).</p>
<table>
<caption><span id="tab:table-2-13">Table 2.13: </span>Characterization of the second axis from second PCA.</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">scale</th>
<th align="left">type</th>
<th align="right">coord</th>
<th align="right">weight</th>
<th align="right">mean</th>
<th align="right">stdev</th>
<th align="right">number</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>teacher2</td>
<td align="left">continuous</td>
<td align="left">active</td>
<td align="right">-0.69</td>
<td align="right">51</td>
<td align="right">1.19</td>
<td align="right">0.37</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>mechanic2</td>
<td align="left">continuous</td>
<td align="left">active</td>
<td align="right">0.72</td>
<td align="right">51</td>
<td align="right">0.96</td>
<td align="right">0.24</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td>bank_clerk2</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.54</td>
<td align="right">51</td>
<td align="right">18749.02</td>
<td align="right">13413.83</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>factory_manager</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.52</td>
<td align="right">51</td>
<td align="right">30933.34</td>
<td align="right">21250.57</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td>engineer</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.51</td>
<td align="right">51</td>
<td align="right">24664.71</td>
<td align="right">14019.08</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td>teacher</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">-0.50</td>
<td align="right">51</td>
<td align="right">16801.96</td>
<td align="right">13243.42</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td>burger_work_time</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.33</td>
<td align="right">51</td>
<td align="right">66.71</td>
<td align="right">97.82</td>
<td align="right">42</td>
</tr>
<tr class="even">
<td>Axis3</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.37</td>
<td align="right">51</td>
<td align="right">0.00</td>
<td align="right">0.57</td>
<td align="right">44</td>
</tr>
<tr class="odd">
<td>Axis1</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.43</td>
<td align="right">51</td>
<td align="right">0.00</td>
<td align="right">3.18</td>
<td align="right">45</td>
</tr>
<tr class="even">
<td>manual_qualified</td>
<td align="left">continuous</td>
<td align="left">supplementary</td>
<td align="right">0.68</td>
<td align="right">51</td>
<td align="right">1.06</td>
<td align="right">0.17</td>
<td align="right">46</td>
</tr>
</tbody>
</table>
</div>
<div id="v-test-and-data-science" class="section level3">
<h3><span class="header-section-number">2.4.5</span> V-test and Data Science</h3>
<p>The v-test values are a quick and fast tool for data science (e.g. automatic exploration of significant associations) for the raw data, as well as for the results from dimension reduction techniques (e.g. PCA) and cluster analysis. When dealing with <em>large</em> data tables, to read complex multidimensional analysis, sorting the elements according to the v-test in decreasing order, will allow us to highlight the relevant features. This enables us to see where are the systemic patterns, which in turn will accumulate progressive knowledge about the data under analyisis.</p>
<p>All the available information in a data table can be ordered according to the v-tests over a fatorial plane. For example, when analyzing survey data, we could include information such as “hour of the interview”, or the interaction between sex-age of the pair interviewer-interviewee, etc. These attributes, located on the factorial planes, and associated with their most significant v-test, form an interesting validation tool of the survey results.</p>
<p>Figure <a href="mechanics.html#fig:fig-2-17">2.17</a> shows the position of the <em>time of interview</em> and the <em>age of interviewer</em>. The “interview in the afternoon”, for instance, is the center of gravity of all the interviewed persons in the afternoon.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-17"></span>
<img src="images/figure-2-17.png" alt="Position of additional information." width="75%" />
<p class="caption">
Figure 2.17: Position of additional information.
</p>
</div>
<p>The v-test allows us to characterize all the significant associations, although we don’t take into account the redundancies nor the dependencies between elements. This fact causes multiple redundancies, and consequently, improves our knowledge about the analyzed data.</p>
<p>As another example, we can consider the trajectory, on a factorial plane, of the categories of <em>age of interviewer</em>, from 1 to 4. Let’s suppose that these categories follow the direction of the first factorial axis, as shown in figure <a href="mechanics.html#fig:fig-2-18">2.18</a>. The form of this trajectory comes from the set of associations between the active elements in the analysis.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-18"></span>
<img src="images/figure-2-18.png" alt="Pattern of a trajectory." width="75%" />
<p class="caption">
Figure 2.18: Pattern of a trajectory.
</p>
</div>
<p>It is possible that the v-test associated to the extreme categories 1 and 4 are high. However, the central categories 2 and 3 will very likely have small v-test values that won’t be significantly different from the origin. Does this mean that we should ignore these “non significant” categories, even though their alignment on the trajetory shows a coherent pattern?</p>
<p>We see that the notion of a “coherent pattern” is implied in the associations among variables. Some elements may have weak v-test values, but these does not imply that they are useless.</p>
<div id="note" class="section level4 unnumbered">
<h4>Note</h4>
<p>The proximity between two categories <em>A</em> and <em>B</em> from two different variables, can be the result from two distinct effects. On one hand, it is possible that both categories share most of the individuals in common, which results in the proximity between their average points. On the other hand, it is possible that the individuals the form each category are different, although they are located in the same region of the plane (see <a href="mechanics.html#fig:fig-2-19">2.19</a>). In both cases, the proximity between categories <em>A</em> and <em>B</em> can be interpreted in terms of the similarity with respect to the active variables among the individuals forming such categories.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-19"></span>
<img src="images/figure-2-19.png" alt="Proximity between two categories." width="80%" />
<p class="caption">
Figure 2.19: Proximity between two categories.
</p>
</div>
<p>For example, two age categories may be close to each other, although they are formed by different individuals. Likewise, the individuals that have a certain voting behavior will be in the same region of the plane as those individuals that consume a certain product; this can be explained because they have the socio-cultural profile without being the same individuals.</p>
</div>
</div>
</div>
<div id="simultaneous-representations" class="section level2">
<h2><span class="header-section-number">2.5</span> Simultaneous Representations</h2>
<div id="old-unit-axes" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Old Unit Axes</h3>
<p>In a Principal Component Analysis the cloud of individuals as well as the cloud of variables are defined in different spaces, with distinct origins and distinct vector basis.</p>
<p>For the cloud of row-points, the origin corresponds to the center of gravity of the individuals. This space is of <span class="math inline">\(p\)</span> dimensions and we denote <span class="math inline">\(\mathbf{u}_{\alpha}\)</span> the corresponding base.</p>
<p>In turn, for the cloud of column-points the origin is the point zero. This space is of <span class="math inline">\(n\)</span> dimensions (although the active variables define a subspace of <span class="math inline">\(p\)</span> dimensions) and denote the factorial axes as <span class="math inline">\(\mathbf{v}_{\alpha}\)</span>.</p>
<p>Because the row-points and the column-points are therefore in different spaces it is impossible to simultaneously visualize them in the same space, in such a way that the inner proximities are respected (without deformations).</p>
<p>However, it is possible to represent the directions defined by each active variable over the base of factorial axes <span class="math inline">\(\mathbf{u}_{\alpha}\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-20"></span>
<img src="images/figure-2-20.png" alt="Old base in original p-dimensional space, and the new based formed by the factorial axes." width="70%" />
<p class="caption">
Figure 2.20: Old base in original p-dimensional space, and the new based formed by the factorial axes.
</p>
</div>
<p>The vectors that define the directions of the original variables are the vectors <span class="math inline">\((1,0,0, \dots)\)</span>, <span class="math inline">\((0,1,0,\dots)\)</span>, <span class="math inline">\((0,0,1,0,\dots)\)</span>, etc.</p>
<p>Let <span class="math inline">\(\mathbf{e_j}\)</span> be the <span class="math inline">\(j\)</span>-th vector of this basis. Its projection on the basis determined by the vector <span class="math inline">\(\mathbf{u}_{\alpha}\)</span> is defined by the scalar product of the vectors:</p>
<p><span class="math display" id="eq:2-19">\[
\mathbf{e_j}^\mathsf{T} \mathbf{u}_{\alpha} = u_{j\alpha}
\tag{2.19}
\]</span></p>
<p>The element <span class="math inline">\(u_{j\alpha}\)</span> is the <span class="math inline">\(j\)</span>-th component of the vector <span class="math inline">\(\mathbf{u}_{\alpha}\)</span>.</p>
<p>The projection of the old axes, defining the directions of the active variables, over a new factorial basis, is given by the components of the eigenvectors <span class="math inline">\(\mathbf{u}_{\alpha}\)</span> from the analysis of row-points.</p>
<p>We can considered an old axis <span class="math inline">\(j\)</span>—direction of the <span class="math inline">\(j\)</span>-th variable—as an artificial “individual” in the space of the individuals. This “individual” has a coordinate 1 in the <span class="math inline">\(j\)</span>-th axis and 0 in the rest of the axes. In this way, the variable-point <span class="math inline">\(j\)</span> can be located in the core of the cloud of row-points of the factorial plane. Its interpretation in straightforward: this point <span class="math inline">\(j\)</span> is the extreme of the unit vector that defines the direction of growth of variable <span class="math inline">\(j\)</span> in the cloud of individuals.</p>
<p>Interestingly, the <span class="math inline">\(p\)</span> variables can be regarded as <span class="math inline">\(p\)</span> unit vectors located in the core of the cloud of row-points. This involves a translation of the original basis to the average point of individuals. Obviously, these <span class="math inline">\(p\)</span> points are on a hypersphere of unit radius.</p>
<p>In the first factorial plane of the cloud of individuals, these <span class="math inline">\(p\)</span> unit vectors will be located inside a circle of unit radius as projected on the orthonormal basis of the active variables.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-21"></span>
<img src="images/figure-2-21.png" alt="Projection of the original axes on the factorial plane with the cloud of row-points." width="70%" />
<p class="caption">
Figure 2.21: Projection of the original axes on the factorial plane with the cloud of row-points.
</p>
</div>
<p>Notice that there is no common unit between the length 1 of the unit vector defined by the <span class="math inline">\(j\)</span>-th variable and the values of the coordinates of the individuals over an axis. Because only the direction is what matters, we can strettch these unit vectors in such a way that the directions defined by them are clearly “readable” in the cloud of row-points.</p>
<p>In our working example, figure <a href="mechanics.html#fig:fig-2-22">2.22</a> shows the simultaneous representation of the cities and the active variables.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-22"></span>
<img src="images/figure-2-22.png" alt="Row-points with directions of growth of the variables (old unit-vector axes)." width="75%" />
<p class="caption">
Figure 2.22: Row-points with directions of growth of the variables (old unit-vector axes).
</p>
</div>
<p>This configuration of variable-points differs from the configuration obtained in section 2.2. Before, the angle between two variables <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span> was a measure of correlation between them. Now, all the angles are square angles; we only observe the projection of these square angles on the factorial plane.</p>
<p>If the arrowhead of the vector representing a variable-point is close to the circumference of radius 1, this means that the direction of growth of this variable is well defined in the factorial plane. Likewise, the individuals that are near the center take values that are close to the average of the variable. In contrast, the individuals that are further from the center, following the direction of growth of a variable, have large values for such variable.</p>
<p>Notice that, if in this simultaneous representation, all the unit vectors form an narrow array around the first factorial axis. This inidicates a <em>size factor</em>. All the variales increase—and decrease—simultaneously in the direction of the first axis.</p>
<div id="about-the-representation-of-variable-points" class="section level4 unnumbered">
<h4>About the representation of variable-points</h4>
<p>The coordinate of the variable <span class="math inline">\(j\)</span> on the axis <span class="math inline">\(\alpha\)</span> is (see formula <a href="mechanics.html#eq:2-10">(2.10)</a>):</p>
<p><span class="math display">\[
\sqrt{\lambda_{\alpha}} \hspace{1mm} u_{j \alpha}
\]</span></p>
<p>The coordinate of the unit vector representing the direction of growth of variable <span class="math inline">\(j\)</span> on the axis <span class="math inline">\(\alpha\)</span>—in the simultaneous representation graph—is:</p>
<p><span class="math display">\[
u_{j \alpha}
\]</span></p>
<p>The similarity between these two formulas implies that their respective graphic displays are also similar. The only difference is a scaling factor of <span class="math inline">\(\sqrt{\lambda_{\alpha}}\)</span>, which is visually reflected as a stretching effect.</p>
<p>For example, the comparison of both clouds of old and new unitary axes is shown in figure <a href="mechanics.html#fig:fig-2-23">2.23</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fig-2-23"></span>
<img src="images/figure-2-23.png" alt="Representation of the variable-points (top) and the old axes (bottom)." width="50%" />
<p class="caption">
Figure 2.23: Representation of the variable-points (top) and the old axes (bottom).
</p>
</div>
<p>This graphical similarity leads to abuse of language in interpretating simultaneous representation (mixing analysis of angles and analysis of growth directions).</p>
<p>Notice that it is not possible to directly display at the same time the supplementary variables in a simultaneous PCA plot of variables-individuals. The supplementary variables do not participate iin the definition of the original basis for the cloud of row-points.</p>
</div>
<div id="in-summary" class="section level4 unnumbered">
<h4>In Summary …</h4>
<p>In every PCA we have two available representations of the variables:</p>
<ol style="list-style-type: decimal">
<li><p>The representation of the cloud of variable-points: each variable is a vector (unit vector if we perform a normalized PCA), and we study the angles between these vectors.</p></li>
<li><p>The simultaneous representation of individuals and active variables: the variable-points are the ends of the orthogonal unit vectors indicating the directions of growth of the variables.</p></li>
</ol>
<p>We should say that these two representations of the variables can be regarded as two extreme situations of a more general representation system introduced by Gabriel (1971). Under this system, commonly known as <strong>biplot</strong>, the data table is decomposed as the product of two matrices: one matrix represents the rows, and the other matrix represents the columns. The biplot involves the joint representation of both elements (rows and columns) in one graphic.</p>

</div>
</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="basic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pca4ds/pca4ds.github.io/edit/master/02-mechanics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
